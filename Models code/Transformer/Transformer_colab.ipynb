{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1CfG14ezEMKQfqB_n8vG2aD4PUh-efKA8","authorship_tag":"ABX9TyMg9zCsfiMkX5tjmeaXHscr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"H8lZVU-HUCGw","colab_type":"code","outputId":"c879956e-756f-4ff2-d44f-fc51efd718f1","executionInfo":{"status":"ok","timestamp":1589400925958,"user_tz":-120,"elapsed":5298,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Wed May 13 20:15:22 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YMjVl_wuUD2z","colab_type":"code","outputId":"58ad9cc8-0c8e-4ac5-b106-e5ac603f98c8","executionInfo":{"status":"ok","timestamp":1589400962768,"user_tz":-120,"elapsed":25986,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh && bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-05-13 20:15:37--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...\n","Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 85055499 (81M) [application/x-sh]\n","Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n","\n","\r          Miniconda   0%[                    ]       0  --.-KB/s               \r         Miniconda3  35%[======>             ]  28.60M   143MB/s               \r        Miniconda3-  85%[================>   ]  69.76M   174MB/s               \rMiniconda3-latest-L 100%[===================>]  81.12M   171MB/s    in 0.5s    \n","\n","2020-05-13 20:15:37 (171 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [85055499/85055499]\n","\n","PREFIX=/usr/local\n","Unpacking payload ...\n","Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n","Solving environment: - \b\bdone\n","\n","## Package Plan ##\n","\n","  environment location: /usr/local\n","\n","  added / updated specs:\n","    - _libgcc_mutex==0.1=main\n","    - asn1crypto==1.3.0=py37_0\n","    - ca-certificates==2020.1.1=0\n","    - certifi==2019.11.28=py37_0\n","    - cffi==1.14.0=py37h2e261b9_0\n","    - chardet==3.0.4=py37_1003\n","    - conda-package-handling==1.6.0=py37h7b6447c_0\n","    - conda==4.8.2=py37_0\n","    - cryptography==2.8=py37h1ba5d50_0\n","    - idna==2.8=py37_0\n","    - ld_impl_linux-64==2.33.1=h53a641e_7\n","    - libedit==3.1.20181209=hc058e9b_0\n","    - libffi==3.2.1=hd88cf55_4\n","    - libgcc-ng==9.1.0=hdf63c60_0\n","    - libstdcxx-ng==9.1.0=hdf63c60_0\n","    - ncurses==6.2=he6710b0_0\n","    - openssl==1.1.1d=h7b6447c_4\n","    - pip==20.0.2=py37_1\n","    - pycosat==0.6.3=py37h7b6447c_0\n","    - pycparser==2.19=py37_0\n","    - pyopenssl==19.1.0=py37_0\n","    - pysocks==1.7.1=py37_0\n","    - python==3.7.6=h0371630_2\n","    - readline==7.0=h7b6447c_5\n","    - requests==2.22.0=py37_1\n","    - ruamel_yaml==0.15.87=py37h7b6447c_0\n","    - setuptools==45.2.0=py37_0\n","    - six==1.14.0=py37_0\n","    - sqlite==3.31.1=h7b6447c_0\n","    - tk==8.6.8=hbc83047_0\n","    - tqdm==4.42.1=py_0\n","    - urllib3==1.25.8=py37_0\n","    - wheel==0.34.2=py37_0\n","    - xz==5.2.4=h14c3975_4\n","    - yaml==0.1.7=had09818_2\n","    - zlib==1.2.11=h7b6447c_3\n","\n","\n","The following NEW packages will be INSTALLED:\n","\n","  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n","  asn1crypto         pkgs/main/linux-64::asn1crypto-1.3.0-py37_0\n","  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.1.1-0\n","  certifi            pkgs/main/linux-64::certifi-2019.11.28-py37_0\n","  cffi               pkgs/main/linux-64::cffi-1.14.0-py37h2e261b9_0\n","  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n","  conda              pkgs/main/linux-64::conda-4.8.2-py37_0\n","  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n","  cryptography       pkgs/main/linux-64::cryptography-2.8-py37h1ba5d50_0\n","  idna               pkgs/main/linux-64::idna-2.8-py37_0\n","  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n","  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n","  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n","  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n","  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n","  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_0\n","  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_4\n","  pip                pkgs/main/linux-64::pip-20.0.2-py37_1\n","  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h7b6447c_0\n","  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n","  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-py37_0\n","  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n","  python             pkgs/main/linux-64::python-3.7.6-h0371630_2\n","  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n","  requests           pkgs/main/linux-64::requests-2.22.0-py37_1\n","  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py37h7b6447c_0\n","  setuptools         pkgs/main/linux-64::setuptools-45.2.0-py37_0\n","  six                pkgs/main/linux-64::six-1.14.0-py37_0\n","  sqlite             pkgs/main/linux-64::sqlite-3.31.1-h7b6447c_0\n","  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n","  tqdm               pkgs/main/noarch::tqdm-4.42.1-py_0\n","  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py37_0\n","  wheel              pkgs/main/linux-64::wheel-0.34.2-py37_0\n","  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n","  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n","  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n","\n","\n","Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\bdone\n","Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n","installation finished.\n","WARNING:\n","    You currently have a PYTHONPATH environment variable set. This may cause\n","    unexpected behavior when running the Python interpreter in Miniconda3.\n","    For best results, please verify that your PYTHONPATH only points to\n","    directories of packages that are compatible with the Python interpreter\n","    in Miniconda3: /usr/local\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a64DFu6GV5bQ","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/usr/local/lib/python3.6/site-packages')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xW5yp435V7kf","colab_type":"code","outputId":"67b2f908-ce7d-43da-a852-4be21b368abd","executionInfo":{"status":"ok","timestamp":1589400968986,"user_tz":-120,"elapsed":30996,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":918}},"source":["!conda install certifi openssl readline setuptools sqlite tk wheel xz zlib -y"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n","Solving environment: | \b\b/ \b\b- \b\bdone\n","\n","## Package Plan ##\n","\n","  environment location: /usr/local\n","\n","  added / updated specs:\n","    - certifi\n","    - openssl\n","    - readline\n","    - setuptools\n","    - sqlite\n","    - tk\n","    - wheel\n","    - xz\n","    - zlib\n","\n","\n","The following packages will be downloaded:\n","\n","    package                    |            build\n","    ---------------------------|-----------------\n","    certifi-2020.4.5.1         |           py37_0         155 KB\n","    conda-4.8.3                |           py37_0         2.8 MB\n","    openssl-1.1.1g             |       h7b6447c_0         2.5 MB\n","    setuptools-46.2.0          |           py37_0         513 KB\n","    sqlite-3.31.1              |       h62c20be_1         1.1 MB\n","    xz-5.2.5                   |       h7b6447c_0         341 KB\n","    ------------------------------------------------------------\n","                                           Total:         7.4 MB\n","\n","The following packages will be UPDATED:\n","\n","  certifi                                 2019.11.28-py37_0 --> 2020.4.5.1-py37_0\n","  conda                                        4.8.2-py37_0 --> 4.8.3-py37_0\n","  openssl                                 1.1.1d-h7b6447c_4 --> 1.1.1g-h7b6447c_0\n","  setuptools                                  45.2.0-py37_0 --> 46.2.0-py37_0\n","  sqlite                                  3.31.1-h7b6447c_0 --> 3.31.1-h62c20be_1\n","  xz                                       5.2.4-h14c3975_4 --> 5.2.5-h7b6447c_0\n","\n","\n","\n","Downloading and Extracting Packages\n","xz-5.2.5             | 341 KB    | : 100% 1.0/1 [00:00<00:00, 10.21it/s]\n","sqlite-3.31.1        | 1.1 MB    | : 100% 1.0/1 [00:00<00:00, 15.99it/s]\n","certifi-2020.4.5.1   | 155 KB    | : 100% 1.0/1 [00:00<00:00, 20.02it/s]\n","openssl-1.1.1g       | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  7.71it/s]\n","setuptools-46.2.0    | 513 KB    | : 100% 1.0/1 [00:00<00:00, 16.02it/s]\n","conda-4.8.3          | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  8.59it/s]\n","Preparing transaction: | \b\bdone\n","Verifying transaction: - \b\b\\ \b\bdone\n","Executing transaction: / \b\bdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ch97dDLVV96s","colab_type":"code","outputId":"f8176392-1c41-4bf3-90b1-702a1ab9cc02","executionInfo":{"status":"ok","timestamp":1589401107592,"user_tz":-120,"elapsed":168995,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":239}},"source":["pip install torch==1.1.0"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting torch==1.1.0\n","  Downloading torch-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (676.9 MB)\n","\u001b[K     |████████████████████████████████| 676.9 MB 3.8 kB/s \n","\u001b[?25hCollecting numpy\n","  Downloading numpy-1.18.4-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n","\u001b[K     |████████████████████████████████| 20.2 MB 1.3 MB/s \n","\u001b[?25hInstalling collected packages: numpy, torch\n","Successfully installed numpy-1.18.4 torch-1.1.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"VcK0E5FOWAlz","colab_type":"code","outputId":"70f0abe4-8e82-48e2-9a2d-42077cc0aaa3","executionInfo":{"status":"ok","timestamp":1589401110632,"user_tz":-120,"elapsed":171161,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["pip install torchtext"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting torchtext\n","  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n","\u001b[?25l\r\u001b[K     |█████                           | 10 kB 32.9 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 2.3 MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/site-packages (from torchtext) (1.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from torchtext) (4.42.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from torchtext) (1.18.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from torchtext) (2.22.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from torchtext) (1.14.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.90-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 14.3 MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->torchtext) (2020.4.5.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->torchtext) (1.25.8)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->torchtext) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->torchtext) (3.0.4)\n","Installing collected packages: sentencepiece, torchtext\n","Successfully installed sentencepiece-0.1.90 torchtext-0.6.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WwFQqn3oWG-M","colab_type":"code","outputId":"54eebcfc-8e8c-4649-bca3-79a37ca84476","executionInfo":{"status":"ok","timestamp":1589401113199,"user_tz":-120,"elapsed":170826,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pip install chardet==3.0.4"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/site-packages (3.0.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rpRVtSMEWSaQ","colab_type":"code","outputId":"19016878-fa2e-4d43-e906-57a8f7fe2a07","executionInfo":{"status":"ok","timestamp":1589401116092,"user_tz":-120,"elapsed":148883,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["pip install future==0.17.1"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Collecting future==0.17.1\n","  Downloading future-0.17.1.tar.gz (829 kB)\n","\u001b[?25l\r\u001b[K     |▍                               | 10 kB 38.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 40 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 51 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 61 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 71 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 81 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 92 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 102 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 112 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 122 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 133 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 143 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 153 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 163 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 174 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 184 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 194 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 204 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 215 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 225 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 235 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 245 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 256 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 266 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 276 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 286 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 296 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 307 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 317 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 327 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 337 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 348 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 358 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 368 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 378 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 389 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 399 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 409 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 419 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 430 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 440 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 450 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 460 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 471 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 481 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 491 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 501 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 512 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 522 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 532 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 542 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 552 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 563 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 573 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 583 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 593 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 604 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 614 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 624 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 634 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 645 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 655 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 665 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 675 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 686 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 696 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 706 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 716 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 727 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 737 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 747 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 757 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 768 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 778 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 788 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 798 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 808 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 819 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 829 kB 9.4 MB/s \n","\u001b[?25hBuilding wheels for collected packages: future\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.17.1-py3-none-any.whl size=488732 sha256=88adb4bb460f7e98de7c3ac69d086782c7192d96bbde150f4929a679de1bedb5\n","  Stored in directory: /root/.cache/pip/wheels/16/4c/84/8a6161d44282ede60ed233d090156c6109a7ab865e49c1c9f6\n","Successfully built future\n","Installing collected packages: future\n","Successfully installed future-0.17.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i0xjUXRhWlyT","colab_type":"code","outputId":"e634be27-76f4-47c2-a4d0-d90c9e724716","executionInfo":{"status":"ok","timestamp":1589401118096,"user_tz":-120,"elapsed":150562,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pip install idna==2.8"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: idna==2.8 in /usr/local/lib/python3.7/site-packages (2.8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GTpvYZXHWmnX","colab_type":"code","outputId":"b4c08ea6-1758-492d-d9d8-ff606d7d0043","executionInfo":{"status":"ok","timestamp":1589401123670,"user_tz":-120,"elapsed":155827,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["pip install opencv-python==4.0.0.21"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Collecting opencv-python==4.0.0.21\n","  Downloading opencv_python-4.0.0.21-cp37-cp37m-manylinux1_x86_64.whl (25.4 MB)\n","\u001b[K     |████████████████████████████████| 25.4 MB 89 kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/site-packages (from opencv-python==4.0.0.21) (1.18.4)\n","Installing collected packages: opencv-python\n","Successfully installed opencv-python-4.0.0.21\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tJYYC3hcWnUv","colab_type":"code","outputId":"2532f193-a996-4c50-a20a-1df54b0858e4","executionInfo":{"status":"ok","timestamp":1589401125892,"user_tz":-120,"elapsed":157751,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":426}},"source":["pip install requests==2.21.0"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Collecting requests==2.21.0\n","  Downloading requests-2.21.0-py2.py3-none-any.whl (57 kB)\n","\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 20 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 40 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 51 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 57 kB 3.8 MB/s \n","\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests==2.21.0) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests==2.21.0) (3.0.4)\n","Collecting urllib3<1.25,>=1.21.1\n","  Downloading urllib3-1.24.3-py2.py3-none-any.whl (118 kB)\n","\u001b[?25l\r\u001b[K     |██▊                             | 10 kB 41.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 20 kB 45.5 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 30 kB 49.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 40 kB 48.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 51 kB 47.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 61 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 71 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 81 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 92 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 102 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 112 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 118 kB 25.1 MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests==2.21.0) (2020.4.5.1)\n","Installing collected packages: urllib3, requests\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.25.8\n","    Uninstalling urllib3-1.25.8:\n","      Successfully uninstalled urllib3-1.25.8\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.22.0\n","    Uninstalling requests-2.22.0:\n","      Successfully uninstalled requests-2.22.0\n","Successfully installed requests-2.21.0 urllib3-1.24.3\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["urllib3"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"dW6-XCnzWn6N","colab_type":"code","outputId":"06f5f098-e8c1-4cc4-8105-748c1c04b14f","executionInfo":{"status":"ok","timestamp":1589401127969,"user_tz":-120,"elapsed":158690,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":239}},"source":["pip install six==1.12.0"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Collecting six==1.12.0\n","  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n","Installing collected packages: six\n","  Attempting uninstall: six\n","    Found existing installation: six 1.14.0\n","    Uninstalling six-1.14.0:\n","      Successfully uninstalled six-1.14.0\n","Successfully installed six-1.12.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["six"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Kpflic5YWo2z","colab_type":"code","outputId":"67239a3f-e2eb-4255-ba3e-ccab3193543c","executionInfo":{"status":"ok","timestamp":1589401130929,"user_tz":-120,"elapsed":161104,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["pip install tqdm==4.31.1"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Collecting tqdm==4.31.1\n","  Downloading tqdm-4.31.1-py2.py3-none-any.whl (48 kB)\n","\u001b[?25l\r\u001b[K     |██████▉                         | 10 kB 30.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 20 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 30 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 40 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 48 kB 3.4 MB/s \n","\u001b[?25hInstalling collected packages: tqdm\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.42.1\n","    Uninstalling tqdm-4.42.1:\n","      Successfully uninstalled tqdm-4.42.1\n","Successfully installed tqdm-4.31.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ndYgg6rNWpeA","colab_type":"code","outputId":"6707aaf1-ab1a-44b6-cdad-ba98364e0c03","executionInfo":{"status":"ok","timestamp":1589401132758,"user_tz":-120,"elapsed":162309,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["pip install urllib3==1.24.1"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Collecting urllib3==1.24.1\n","  Downloading urllib3-1.24.1-py2.py3-none-any.whl (118 kB)\n","\u001b[?25l\r\u001b[K     |██▊                             | 10 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 20 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 30 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 40 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 51 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 61 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 71 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 81 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 92 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 102 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 112 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 118 kB 8.5 MB/s \n","\u001b[?25hInstalling collected packages: urllib3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed urllib3-1.24.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bYMgxxihYGFl","colab_type":"code","outputId":"41de4d46-9e43-4d45-85e6-f2b0e1499c38","executionInfo":{"status":"ok","timestamp":1589401137538,"user_tz":-120,"elapsed":166460,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["pip install nltk"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Collecting nltk\n","  Downloading nltk-3.5.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 8.1 MB/s \n","\u001b[?25hCollecting click\n","  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 1.5 MB/s \n","\u001b[?25hCollecting joblib\n","  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n","\u001b[K     |████████████████████████████████| 294 kB 41.6 MB/s \n","\u001b[?25hCollecting regex\n","  Downloading regex-2020.5.13-cp37-cp37m-manylinux2010_x86_64.whl (675 kB)\n","\u001b[K     |████████████████████████████████| 675 kB 46.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from nltk) (4.31.1)\n","Building wheels for collected packages: nltk\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434678 sha256=599b66c997f59230d495939568b2de393f04f23bf11143c8dc7fb094d1c22aff\n","  Stored in directory: /root/.cache/pip/wheels/45/6c/46/a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266\n","Successfully built nltk\n","Installing collected packages: click, joblib, regex, nltk\n","Successfully installed click-7.1.2 joblib-0.14.1 nltk-3.5 regex-2020.5.13\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YHyPiBMQYLUr","colab_type":"code","colab":{}},"source":["import nltk"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKcc1HVmYLqw","colab_type":"code","outputId":"44052dc1-1f08-45e5-cfc2-6e44438e4f56","executionInfo":{"status":"ok","timestamp":1589401138988,"user_tz":-120,"elapsed":166546,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["nltk.download('punkt')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"nSXTNUgMWp59","colab_type":"code","outputId":"f8f3ffcf-b8f0-4548-d95d-070a8c6ab21e","executionInfo":{"status":"ok","timestamp":1589139442818,"user_tz":-120,"elapsed":244490,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["!python /content/drive/My\\ Drive/transformer/code/preprocess.py \\\n","                    -train_src /content/drive/My\\ Drive/transformer/data/multi-news-original-src-cleaned-no-newlinechar-word_tokenizer_1000/train.src.cleaned.tokenized.truncated1000 \\\n","                    -train_tgt /content/drive/My\\ Drive/transformer/data/multi-news-original-src-cleaned-no-newlinechar-word_tokenizer_1000/train.tgt.tokenized  \\\n","                    -valid_src /content/drive/My\\ Drive/transformer/data/multi-news-original-src-cleaned-no-newlinechar-word_tokenizer_1000/val.src.cleaned.tokenized.truncated1000    \\\n","                    -valid_tgt /content/drive/My\\ Drive/transformer/data/multi-news-original-src-cleaned-no-newlinechar-word_tokenizer_1000/val.tgt.tokenized    \\\n","                    -save_data /content/drive/My\\ Drive/transformer/data/transformer_prep_data \\\n","                    -src_seq_length 10000 \\\n","                    -tgt_seq_length 10000 \\\n","                    -src_seq_length_trunc 500 \\\n","                    -tgt_seq_length_trunc 300 \\\n","                    -dynamic_dict \\\n","                    -share_vocab \\\n","                    -max_shard_size 100000000"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[2020-05-10 19:33:19,377 INFO] Extracting features...\n","[2020-05-10 19:33:19,388 INFO]  * number of source features: 0.\n","[2020-05-10 19:33:19,389 INFO]  * number of target features: 0.\n","[2020-05-10 19:33:19,389 INFO] Building `Fields` object...\n","[2020-05-10 19:33:19,389 INFO] Building & saving training data...\n","[2020-05-10 19:33:19,389 INFO]  * divide corpus into shards and build dataset separately (shard_size = 100000000 bytes).\n","[2020-05-10 19:33:58,337 INFO]  * saving train data shard to /content/drive/My Drive/transformer/data/transformer_prep_data.train.1.pt.\n","[2020-05-10 19:35:23,101 INFO]  * saving train data shard to /content/drive/My Drive/transformer/data/transformer_prep_data.train.2.pt.\n","[2020-05-10 19:36:15,456 INFO]  * saving train data shard to /content/drive/My Drive/transformer/data/transformer_prep_data.train.3.pt.\n","[2020-05-10 19:36:24,340 INFO] Building & saving validation data...\n","[2020-05-10 19:36:24,341 INFO]  * divide corpus into shards and build dataset separately (shard_size = 100000000 bytes).\n","[2020-05-10 19:36:35,518 INFO]  * saving valid data shard to /content/drive/My Drive/transformer/data/transformer_prep_data.valid.1.pt.\n","[2020-05-10 19:36:46,747 INFO] Building & saving vocabulary...\n","[2020-05-10 19:36:54,856 INFO]  * reloading /content/drive/My Drive/transformer/data/transformer_prep_data.train.1.pt.\n","[2020-05-10 19:37:07,080 INFO]  * reloading /content/drive/My Drive/transformer/data/transformer_prep_data.train.2.pt.\n","[2020-05-10 19:37:13,345 INFO]  * reloading /content/drive/My Drive/transformer/data/transformer_prep_data.train.3.pt.\n","[2020-05-10 19:37:16,528 INFO]  * reloading /content/drive/My Drive/transformer/data/transformer_prep_data.valid.1.pt.\n","[2020-05-10 19:37:17,989 INFO]  * tgt vocab size: 50004.\n","[2020-05-10 19:37:18,769 INFO]  * src vocab size: 50002.\n","[2020-05-10 19:37:18,769 INFO]  * merging src and tgt vocab...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Wi-fX-GEXQGV","colab_type":"code","outputId":"c8121f21-1039-4ad3-a00c-cdf972ca53b7","executionInfo":{"status":"ok","timestamp":1588971521827,"user_tz":-120,"elapsed":10374458,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python /content/drive/My\\ Drive/transformer/code/train.py -save_model /content/drive/My\\ Drive/transformer\\model_transformer_1000\\transformer_1000 \\\n","        -data /content/drive/My\\ Drive/transformer/data/transformer_prep_data \\\n","        -copy_attn -word_vec_size 512 -rnn_size 512 -layers 4 -encoder_type transformer -decoder_type transformer -position_encoding \\\n","        -train_steps 50000 -warmup_steps 8000 -learning_rate 2 -decay_method noam -label_smoothing 0.1 -max_grad_norm 0 -dropout 0.2 \\\n","        -batch_size 4096 -optim adam -adam_beta2 0.998 -param_init 0 -batch_type tokens -normalization tokens -max_generator_batches 2 \\\n","        -accum_count 4 -share_embeddings -param_init_glorot -seed 777 -world_size 1 -gpu_ranks 0 -save_checkpoint_steps 2000"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[2020-05-10 19:52:43,976 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","[2020-05-10 19:52:44,221 INFO]  * vocabulary size. source = 50004; target = 50004\n","[2020-05-10 19:52:44,222 INFO] Building model...\n","[2020-05-10 19:52:49,437 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(50004, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.2)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm): LayerNorm()\n","        (dropout): Dropout(p=0.2)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm): LayerNorm()\n","        (dropout): Dropout(p=0.2)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm): LayerNorm()\n","        (dropout): Dropout(p=0.2)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm): LayerNorm()\n","        (dropout): Dropout(p=0.2)\n","      )\n","    )\n","    (layer_norm): LayerNorm()\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(50004, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.2)\n","        )\n","      )\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm()\n","        (layer_norm_2): LayerNorm()\n","        (drop): Dropout(p=0.2)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm()\n","        (layer_norm_2): LayerNorm()\n","        (drop): Dropout(p=0.2)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm()\n","        (layer_norm_2): LayerNorm()\n","        (drop): Dropout(p=0.2)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm()\n","        (layer_norm_2): LayerNorm()\n","        (drop): Dropout(p=0.2)\n","      )\n","    )\n","    (copy_attn): GlobalAttention(\n","      (linear_in): Linear(in_features=512, out_features=512, bias=False)\n","      (linear_out): Linear(in_features=1024, out_features=512, bias=False)\n","    )\n","    (layer_norm): LayerNorm()\n","  )\n","  (generator): CopyGenerator(\n","    (linear): Linear(in_features=512, out_features=50004, bias=True)\n","    (linear_copy): Linear(in_features=512, out_features=1, bias=True)\n","    (softmax): Softmax()\n","    (sigmoid): Sigmoid()\n","  )\n",")\n","[2020-05-10 19:52:49,461 INFO] encoder: 38212608\n","[2020-05-10 19:52:49,461 INFO] decoder: 43256149\n","[2020-05-10 19:52:49,461 INFO] * number of parameters: 81468757\n","[2020-05-10 19:52:49,463 INFO] Start training...\n","[2020-05-10 19:52:58,486 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","/usr/local/lib/python3.7/site-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  var = torch.tensor(arr, dtype=self.dtype, device=device)\n","[2020-05-10 20:01:57,692 INFO] Step 50/50000; acc:   5.19; ppl: 1424.38; xent: 7.26; lr: 0.00001; 1403/686 tok/s;    539 sec\n","[2020-05-10 20:11:03,035 INFO] Step 100/50000; acc:   5.33; ppl: 1344.97; xent: 7.20; lr: 0.00001; 1891/705 tok/s;   1085 sec\n","[2020-05-10 20:19:56,694 INFO] Step 150/50000; acc:   5.40; ppl: 1533.87; xent: 7.34; lr: 0.00002; 1580/732 tok/s;   1618 sec\n","[2020-05-10 20:29:02,428 INFO] Step 200/50000; acc:   5.70; ppl: 1070.18; xent: 6.98; lr: 0.00002; 1389/733 tok/s;   2164 sec\n","[2020-05-10 20:38:04,643 INFO] Step 250/50000; acc:   5.08; ppl: 763.80; xent: 6.64; lr: 0.00003; 1723/714 tok/s;   2706 sec\n","[2020-05-10 20:47:12,419 INFO] Step 300/50000; acc:   5.12; ppl: 726.70; xent: 6.59; lr: 0.00004; 1426/752 tok/s;   3254 sec\n","[2020-05-10 20:56:22,210 INFO] Step 350/50000; acc:   4.69; ppl: 649.44; xent: 6.48; lr: 0.00004; 1369/763 tok/s;   3804 sec\n","[2020-05-10 21:05:31,732 INFO] Step 400/50000; acc:   5.52; ppl: 468.36; xent: 6.15; lr: 0.00005; 1467/699 tok/s;   4353 sec\n","[2020-05-10 21:14:43,721 INFO] Step 450/50000; acc:   6.13; ppl: 491.62; xent: 6.20; lr: 0.00006; 1396/749 tok/s;   4905 sec\n","[2020-05-10 21:23:58,118 INFO] Step 500/50000; acc:   8.00; ppl: 470.90; xent: 6.15; lr: 0.00006; 1565/739 tok/s;   5460 sec\n","[2020-05-10 21:33:00,002 INFO] Step 550/50000; acc:   7.95; ppl: 476.95; xent: 6.17; lr: 0.00007; 1475/745 tok/s;   6002 sec\n","[2020-05-10 21:41:58,011 INFO] Step 600/50000; acc:   9.25; ppl: 437.66; xent: 6.08; lr: 0.00007; 1396/752 tok/s;   6540 sec\n","[2020-05-10 21:46:58,493 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.2.pt, number of examples: 20478\n","[2020-05-10 21:51:11,445 INFO] Step 650/50000; acc:   9.22; ppl: 458.28; xent: 6.13; lr: 0.00008; 1454/746 tok/s;   7093 sec\n","[2020-05-10 22:00:21,099 INFO] Step 700/50000; acc:  10.08; ppl: 363.40; xent: 5.90; lr: 0.00009; 1412/755 tok/s;   7643 sec\n","[2020-05-10 22:09:12,013 INFO] Step 750/50000; acc:  11.09; ppl: 365.98; xent: 5.90; lr: 0.00009; 1605/727 tok/s;   8174 sec\n","[2020-05-10 22:18:18,080 INFO] Step 800/50000; acc:  11.92; ppl: 350.83; xent: 5.86; lr: 0.00010; 1404/736 tok/s;   8720 sec\n","[2020-05-10 22:27:15,110 INFO] Step 850/50000; acc:  13.38; ppl: 308.63; xent: 5.73; lr: 0.00010; 1720/721 tok/s;   9257 sec\n","[2020-05-10 22:36:20,217 INFO] Step 900/50000; acc:  13.58; ppl: 277.91; xent: 5.63; lr: 0.00011; 1438/744 tok/s;   9802 sec\n","[2020-05-10 22:45:26,586 INFO] Step 950/50000; acc:  14.27; ppl: 297.05; xent: 5.69; lr: 0.00012; 1500/747 tok/s;  10348 sec\n","[2020-05-10 22:54:39,752 INFO] Step 1000/50000; acc:  14.08; ppl: 257.99; xent: 5.55; lr: 0.00012; 1465/748 tok/s;  10901 sec\n","[2020-05-10 23:03:56,765 INFO] Step 1050/50000; acc:  14.76; ppl: 227.84; xent: 5.43; lr: 0.00013; 1451/746 tok/s;  11458 sec\n","[2020-05-10 23:13:04,293 INFO] Step 1100/50000; acc:  14.02; ppl: 238.05; xent: 5.47; lr: 0.00014; 1757/722 tok/s;  12006 sec\n","[2020-05-10 23:22:13,488 INFO] Step 1150/50000; acc:  14.95; ppl: 214.11; xent: 5.37; lr: 0.00014; 1524/663 tok/s;  12555 sec\n","[2020-05-10 23:31:28,690 INFO] Step 1200/50000; acc:  16.31; ppl: 199.71; xent: 5.30; lr: 0.00015; 1789/678 tok/s;  13110 sec\n","[2020-05-10 23:40:45,458 INFO] Step 1250/50000; acc:  15.18; ppl: 207.67; xent: 5.34; lr: 0.00015; 1513/749 tok/s;  13667 sec\n","[2020-05-10 23:41:53,030 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.3.pt, number of examples: 4074\n","[2020-05-10 23:49:47,971 INFO] Step 1300/50000; acc:  15.32; ppl: 222.43; xent: 5.40; lr: 0.00016; 1396/760 tok/s;  14209 sec\n","[2020-05-10 23:59:00,915 INFO] Step 1350/50000; acc:  16.34; ppl: 195.25; xent: 5.27; lr: 0.00017; 1593/720 tok/s;  14762 sec\n","[2020-05-11 00:05:11,801 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","[2020-05-11 00:08:54,654 INFO] Step 1400/50000; acc:  16.03; ppl: 184.15; xent: 5.22; lr: 0.00017; 1370/757 tok/s;  15356 sec\n","[2020-05-11 00:17:52,910 INFO] Step 1450/50000; acc:  16.00; ppl: 188.49; xent: 5.24; lr: 0.00018; 1708/733 tok/s;  15894 sec\n","[2020-05-11 00:26:56,752 INFO] Step 1500/50000; acc:  16.36; ppl: 176.68; xent: 5.17; lr: 0.00019; 1264/641 tok/s;  16438 sec\n","[2020-05-11 00:36:00,638 INFO] Step 1550/50000; acc:  15.93; ppl: 187.20; xent: 5.23; lr: 0.00019; 1215/731 tok/s;  16982 sec\n","[2020-05-11 00:45:18,384 INFO] Step 1600/50000; acc:  16.18; ppl: 183.13; xent: 5.21; lr: 0.00020; 1394/757 tok/s;  17540 sec\n","[2020-05-11 00:54:05,544 INFO] Step 1650/50000; acc:  17.30; ppl: 139.99; xent: 4.94; lr: 0.00020; 1375/707 tok/s;  18067 sec\n","[2020-05-11 01:03:24,504 INFO] Step 1700/50000; acc:  17.48; ppl: 140.67; xent: 4.95; lr: 0.00021; 1667/691 tok/s;  18626 sec\n","[2020-05-11 01:12:48,188 INFO] Step 1750/50000; acc:  17.68; ppl: 151.82; xent: 5.02; lr: 0.00022; 1158/700 tok/s;  19190 sec\n","[2020-05-11 01:21:52,147 INFO] Step 1800/50000; acc:  17.22; ppl: 167.10; xent: 5.12; lr: 0.00022; 1315/745 tok/s;  19734 sec\n","[2020-05-11 01:30:55,452 INFO] Step 1850/50000; acc:  17.67; ppl: 157.97; xent: 5.06; lr: 0.00023; 1463/712 tok/s;  20277 sec\n","[2020-05-11 01:40:18,755 INFO] Step 1900/50000; acc:  18.67; ppl: 134.86; xent: 4.90; lr: 0.00023; 1434/681 tok/s;  20840 sec\n","[2020-05-11 01:49:26,198 INFO] Step 1950/50000; acc:  20.00; ppl: 115.29; xent: 4.75; lr: 0.00024; 1802/719 tok/s;  21388 sec\n","[2020-05-11 01:58:37,319 INFO] Step 2000/50000; acc:  18.58; ppl: 138.82; xent: 4.93; lr: 0.00025; 1478/742 tok/s;  21939 sec\n","[2020-05-11 01:58:37,320 INFO] Saving checkpoint /content/drive/My Drive/transformermodel_transformer_1000transformer_1000_step_2000.pt\n","[2020-05-11 02:00:21,390 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.2.pt, number of examples: 20478\n","[2020-05-11 02:08:24,636 INFO] Step 2050/50000; acc:  18.59; ppl: 147.12; xent: 4.99; lr: 0.00025; 1496/715 tok/s;  22526 sec\n","[2020-05-11 02:17:39,413 INFO] Step 2100/50000; acc:  19.46; ppl: 139.04; xent: 4.93; lr: 0.00026; 1340/703 tok/s;  23081 sec\n","[2020-05-11 02:26:39,879 INFO] Step 2150/50000; acc:  19.68; ppl: 125.81; xent: 4.83; lr: 0.00027; 1652/702 tok/s;  23621 sec\n","[2020-05-11 02:35:52,071 INFO] Step 2200/50000; acc:  20.58; ppl: 126.31; xent: 4.84; lr: 0.00027; 1274/729 tok/s;  24174 sec\n","[2020-05-11 02:44:56,453 INFO] Step 2250/50000; acc:  20.08; ppl: 120.22; xent: 4.79; lr: 0.00028; 1355/737 tok/s;  24718 sec\n","[2020-05-11 02:54:08,962 INFO] Step 2300/50000; acc:  19.96; ppl: 107.55; xent: 4.68; lr: 0.00028; 1588/735 tok/s;  25270 sec\n","[2020-05-11 03:03:10,721 INFO] Step 2350/50000; acc:  20.61; ppl: 107.37; xent: 4.68; lr: 0.00029; 1706/726 tok/s;  25812 sec\n","[2020-05-11 03:12:16,399 INFO] Step 2400/50000; acc:  19.84; ppl: 134.57; xent: 4.90; lr: 0.00030; 1407/757 tok/s;  26358 sec\n","[2020-05-11 03:21:18,188 INFO] Step 2450/50000; acc:  20.68; ppl: 108.90; xent: 4.69; lr: 0.00030; 1367/704 tok/s;  26900 sec\n","[2020-05-11 03:30:22,425 INFO] Step 2500/50000; acc:  20.43; ppl: 117.12; xent: 4.76; lr: 0.00031; 1325/770 tok/s;  27444 sec\n","[2020-05-11 03:39:15,930 INFO] Step 2550/50000; acc:  21.28; ppl: 105.55; xent: 4.66; lr: 0.00031; 1441/757 tok/s;  27977 sec\n","[2020-05-11 03:48:05,818 INFO] Step 2600/50000; acc:  22.11; ppl: 91.35; xent: 4.51; lr: 0.00032; 1829/634 tok/s;  28507 sec\n","[2020-05-11 03:54:53,729 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.3.pt, number of examples: 4074\n","[2020-05-11 03:57:03,188 INFO] Step 2650/50000; acc:  21.76; ppl: 100.00; xent: 4.61; lr: 0.00033; 1423/763 tok/s;  29045 sec\n","[2020-05-11 04:06:05,556 INFO] Step 2700/50000; acc:  21.52; ppl: 105.24; xent: 4.66; lr: 0.00033; 1773/725 tok/s;  29587 sec\n","[2020-05-11 04:14:55,377 INFO] Step 2750/50000; acc:  22.90; ppl: 87.18; xent: 4.47; lr: 0.00034; 1685/725 tok/s;  30117 sec\n","[2020-05-11 04:17:30,721 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","[2020-05-11 04:24:08,600 INFO] Step 2800/50000; acc:  21.65; ppl: 100.52; xent: 4.61; lr: 0.00035; 1441/756 tok/s;  30670 sec\n","[2020-05-11 04:33:11,778 INFO] Step 2850/50000; acc:  21.61; ppl: 100.82; xent: 4.61; lr: 0.00035; 1251/766 tok/s;  31213 sec\n","[2020-05-11 04:42:02,621 INFO] Step 2900/50000; acc:  24.10; ppl: 80.14; xent: 4.38; lr: 0.00036; 1303/686 tok/s;  31744 sec\n","[2020-05-11 04:50:51,506 INFO] Step 2950/50000; acc:  22.85; ppl: 89.66; xent: 4.50; lr: 0.00036; 1441/752 tok/s;  32273 sec\n","[2020-05-11 04:59:40,545 INFO] Step 3000/50000; acc:  23.06; ppl: 89.75; xent: 4.50; lr: 0.00037; 1568/739 tok/s;  32802 sec\n","[2020-05-11 05:08:36,764 INFO] Step 3050/50000; acc:  22.47; ppl: 98.00; xent: 4.58; lr: 0.00038; 1417/748 tok/s;  33338 sec\n","[2020-05-11 05:17:31,725 INFO] Step 3100/50000; acc:  22.84; ppl: 94.26; xent: 4.55; lr: 0.00038; 1369/752 tok/s;  33873 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zeeFGWenbl2u","colab_type":"code","outputId":"1345d2a0-bf83-4b92-edb7-b9b9da5bc7da","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python /content/drive/My\\ Drive/transformer/code/train.py -save_model /content/drive/My\\ Drive/transformer/model_transformer_1000/transformer_1000 \\\n","        -data /content/drive/My\\ Drive/transformer/data/transformer_prep_data \\\n","        -copy_attn -word_vec_size 512 -rnn_size 512 -layers 4 -encoder_type transformer -decoder_type transformer -position_encoding \\\n","        -train_steps 50000 -warmup_steps 8000 -learning_rate 2 -decay_method noam -label_smoothing 0.1 -max_grad_norm 0 -dropout 0.2 \\\n","        -batch_size 4096 -optim adam -adam_beta2 0.998 -param_init 0 -batch_type tokens -normalization tokens -max_generator_batches 2 \\\n","        -accum_count 4 -share_embeddings -param_init_glorot -seed 777 -world_size 1 -gpu_ranks 0 -save_checkpoint_steps 1000 -train_from /content/drive/My\\ Drive/transformer/model_transformer_1000/transformer_1000_step_2000.pt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[2020-05-11 18:26:42,214 INFO] Loading checkpoint from /content/drive/My Drive/transformer/model_transformer_1000/transformer_1000_step_2000.pt\n","[2020-05-11 18:27:02,789 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","[2020-05-11 18:27:02,789 INFO] Loading vocab from checkpoint at /content/drive/My Drive/transformer/model_transformer_1000/transformer_1000_step_2000.pt.\n","[2020-05-11 18:27:02,847 INFO]  * vocabulary size. source = 50004; target = 50004\n","[2020-05-11 18:27:02,847 INFO] Building model...\n","[2020-05-11 18:27:13,453 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(50004, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.2)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm): LayerNorm()\n","        (dropout): Dropout(p=0.2)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm): LayerNorm()\n","        (dropout): Dropout(p=0.2)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm): LayerNorm()\n","        (dropout): Dropout(p=0.2)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm): LayerNorm()\n","        (dropout): Dropout(p=0.2)\n","      )\n","    )\n","    (layer_norm): LayerNorm()\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(50004, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.2)\n","        )\n","      )\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm()\n","        (layer_norm_2): LayerNorm()\n","        (drop): Dropout(p=0.2)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm()\n","        (layer_norm_2): LayerNorm()\n","        (drop): Dropout(p=0.2)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm()\n","        (layer_norm_2): LayerNorm()\n","        (drop): Dropout(p=0.2)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm()\n","        (layer_norm_2): LayerNorm()\n","        (drop): Dropout(p=0.2)\n","      )\n","    )\n","    (copy_attn): GlobalAttention(\n","      (linear_in): Linear(in_features=512, out_features=512, bias=False)\n","      (linear_out): Linear(in_features=1024, out_features=512, bias=False)\n","    )\n","    (layer_norm): LayerNorm()\n","  )\n","  (generator): CopyGenerator(\n","    (linear): Linear(in_features=512, out_features=50004, bias=True)\n","    (linear_copy): Linear(in_features=512, out_features=1, bias=True)\n","    (softmax): Softmax()\n","    (sigmoid): Sigmoid()\n","  )\n",")\n","[2020-05-11 18:27:13,456 INFO] encoder: 38212608\n","[2020-05-11 18:27:13,456 INFO] decoder: 43256149\n","[2020-05-11 18:27:13,456 INFO] * number of parameters: 81468757\n","[2020-05-11 18:27:13,947 INFO] Start training...\n","[2020-05-11 18:27:21,172 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","/usr/local/lib/python3.7/site-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  var = torch.tensor(arr, dtype=self.dtype, device=device)\n","[2020-05-11 18:30:51,288 INFO] Step 2050/50000; acc:  19.04; ppl: 117.47; xent: 4.77; lr: 0.00025; 3633/1778 tok/s;    210 sec\n","[2020-05-11 18:34:32,698 INFO] Step 2100/50000; acc:  19.33; ppl: 119.87; xent: 4.79; lr: 0.00026; 4518/1684 tok/s;    432 sec\n","[2020-05-11 18:38:12,775 INFO] Step 2150/50000; acc:  19.10; ppl: 139.38; xent: 4.94; lr: 0.00027; 3743/1733 tok/s;    652 sec\n","[2020-05-11 18:42:01,314 INFO] Step 2200/50000; acc:  20.30; ppl: 124.14; xent: 4.82; lr: 0.00027; 3336/1761 tok/s;    880 sec\n","[2020-05-11 18:45:36,271 INFO] Step 2250/50000; acc:  19.26; ppl: 116.08; xent: 4.75; lr: 0.00028; 4316/1789 tok/s;   1095 sec\n","[2020-05-11 18:49:11,680 INFO] Step 2300/50000; acc:  20.40; ppl: 118.44; xent: 4.77; lr: 0.00028; 3556/1874 tok/s;   1311 sec\n","[2020-05-11 18:52:47,832 INFO] Step 2350/50000; acc:  20.46; ppl: 125.28; xent: 4.83; lr: 0.00029; 3361/1874 tok/s;   1527 sec\n","[2020-05-11 18:56:22,400 INFO] Step 2400/50000; acc:  21.30; ppl: 90.69; xent: 4.51; lr: 0.00030; 3721/1773 tok/s;   1741 sec\n","[2020-05-11 18:59:58,582 INFO] Step 2450/50000; acc:  21.06; ppl: 100.21; xent: 4.61; lr: 0.00030; 3476/1865 tok/s;   1957 sec\n","[2020-05-11 19:03:31,166 INFO] Step 2500/50000; acc:  21.33; ppl: 100.40; xent: 4.61; lr: 0.00031; 4097/1934 tok/s;   2170 sec\n","[2020-05-11 19:06:56,924 INFO] Step 2550/50000; acc:  20.57; ppl: 110.75; xent: 4.71; lr: 0.00031; 3851/1945 tok/s;   2376 sec\n","[2020-05-11 19:10:24,376 INFO] Step 2600/50000; acc:  21.16; ppl: 102.78; xent: 4.63; lr: 0.00032; 3673/1978 tok/s;   2583 sec\n","[2020-05-11 19:12:27,978 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.2.pt, number of examples: 20478\n","[2020-05-11 19:14:05,908 INFO] Step 2650/50000; acc:  20.30; ppl: 128.05; xent: 4.85; lr: 0.00033; 3812/1955 tok/s;   2805 sec\n","[2020-05-11 19:17:34,899 INFO] Step 2700/50000; acc:  21.95; ppl: 97.59; xent: 4.58; lr: 0.00033; 3730/1993 tok/s;   3014 sec\n","[2020-05-11 19:20:55,093 INFO] Step 2750/50000; acc:  21.77; ppl: 102.33; xent: 4.63; lr: 0.00034; 4287/1942 tok/s;   3214 sec\n","[2020-05-11 19:24:21,846 INFO] Step 2800/50000; acc:  21.70; ppl: 109.51; xent: 4.70; lr: 0.00035; 3742/1961 tok/s;   3421 sec\n","[2020-05-11 19:27:45,437 INFO] Step 2850/50000; acc:  21.96; ppl: 102.58; xent: 4.63; lr: 0.00035; 4556/1911 tok/s;   3624 sec\n","[2020-05-11 19:31:12,128 INFO] Step 2900/50000; acc:  22.70; ppl: 96.99; xent: 4.57; lr: 0.00036; 3787/1958 tok/s;   3831 sec\n","[2020-05-11 19:34:38,516 INFO] Step 2950/50000; acc:  22.29; ppl: 102.85; xent: 4.63; lr: 0.00036; 3951/1967 tok/s;   4037 sec\n","[2020-05-11 19:38:06,729 INFO] Step 3000/50000; acc:  22.29; ppl: 89.69; xent: 4.50; lr: 0.00037; 3873/1977 tok/s;   4246 sec\n","[2020-05-11 19:38:06,730 INFO] Saving checkpoint /content/drive/My Drive/transformer/model_transformer_1000/transformer_1000_step_3000.pt\n","[2020-05-11 19:41:41,300 INFO] Step 3050/50000; acc:  24.25; ppl: 80.27; xent: 4.39; lr: 0.00038; 3767/1938 tok/s;   4460 sec\n","[2020-05-11 19:45:11,238 INFO] Step 3100/50000; acc:  22.58; ppl: 87.03; xent: 4.47; lr: 0.00038; 4581/1883 tok/s;   4670 sec\n","[2020-05-11 19:48:38,466 INFO] Step 3150/50000; acc:  24.81; ppl: 75.19; xent: 4.32; lr: 0.00039; 4159/1809 tok/s;   4877 sec\n","[2020-05-11 19:52:05,043 INFO] Step 3200/50000; acc:  25.89; ppl: 74.01; xent: 4.30; lr: 0.00040; 4962/1881 tok/s;   5084 sec\n","[2020-05-11 19:55:26,796 INFO] Step 3250/50000; acc:  24.43; ppl: 76.40; xent: 4.34; lr: 0.00040; 3999/1980 tok/s;   5286 sec\n","[2020-05-11 19:56:05,126 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.3.pt, number of examples: 4074\n","[2020-05-11 19:59:06,227 INFO] Step 3300/50000; acc:  24.47; ppl: 82.10; xent: 4.41; lr: 0.00041; 3647/1986 tok/s;   5505 sec\n","[2020-05-11 20:02:30,893 INFO] Step 3350/50000; acc:  25.26; ppl: 76.75; xent: 4.34; lr: 0.00041; 4242/1917 tok/s;   5710 sec\n","[2020-05-11 20:04:49,334 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","[2020-05-11 20:06:07,556 INFO] Step 3400/50000; acc:  26.05; ppl: 65.26; xent: 4.18; lr: 0.00042; 3601/1990 tok/s;   5926 sec\n","[2020-05-11 20:09:33,995 INFO] Step 3450/50000; acc:  26.11; ppl: 67.23; xent: 4.21; lr: 0.00043; 4444/1907 tok/s;   6133 sec\n","[2020-05-11 20:13:00,500 INFO] Step 3500/50000; acc:  25.61; ppl: 69.03; xent: 4.23; lr: 0.00043; 3575/1811 tok/s;   6339 sec\n","[2020-05-11 20:16:21,090 INFO] Step 3550/50000; acc:  24.39; ppl: 75.39; xent: 4.32; lr: 0.00044; 3355/2020 tok/s;   6540 sec\n","[2020-05-11 20:19:42,406 INFO] Step 3600/50000; acc:  25.22; ppl: 71.51; xent: 4.27; lr: 0.00044; 3670/1993 tok/s;   6741 sec\n","[2020-05-11 20:23:02,854 INFO] Step 3650/50000; acc:  29.45; ppl: 50.99; xent: 3.93; lr: 0.00045; 3671/1887 tok/s;   6942 sec\n","[2020-05-11 20:26:28,657 INFO] Step 3700/50000; acc:  27.38; ppl: 54.85; xent: 4.00; lr: 0.00046; 4573/1895 tok/s;   7147 sec\n","[2020-05-11 20:29:50,699 INFO] Step 3750/50000; acc:  28.06; ppl: 56.83; xent: 4.04; lr: 0.00046; 3177/1920 tok/s;   7350 sec\n","[2020-05-11 20:33:16,818 INFO] Step 3800/50000; acc:  26.97; ppl: 68.14; xent: 4.22; lr: 0.00047; 3436/1946 tok/s;   7556 sec\n","[2020-05-11 20:36:43,402 INFO] Step 3850/50000; acc:  25.27; ppl: 70.57; xent: 4.26; lr: 0.00048; 3896/1896 tok/s;   7762 sec\n","[2020-05-11 20:40:13,400 INFO] Step 3900/50000; acc:  28.68; ppl: 53.65; xent: 3.98; lr: 0.00048; 4041/1920 tok/s;   7972 sec\n","[2020-05-11 20:43:38,255 INFO] Step 3950/50000; acc:  30.73; ppl: 46.06; xent: 3.83; lr: 0.00049; 4682/1868 tok/s;   8177 sec\n","[2020-05-11 20:47:07,544 INFO] Step 4000/50000; acc:  27.52; ppl: 61.28; xent: 4.12; lr: 0.00049; 3927/1973 tok/s;   8386 sec\n","[2020-05-11 20:47:07,545 INFO] Saving checkpoint /content/drive/My Drive/transformer/model_transformer_1000/transformer_1000_step_4000.pt\n","[2020-05-11 20:48:02,445 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.2.pt, number of examples: 20478\n","[2020-05-11 20:50:58,011 INFO] Step 4050/50000; acc:  26.07; ppl: 68.85; xent: 4.23; lr: 0.00050; 4090/1955 tok/s;   8617 sec\n","[2020-05-11 20:54:23,234 INFO] Step 4100/50000; acc:  27.34; ppl: 64.67; xent: 4.17; lr: 0.00051; 3812/1999 tok/s;   8822 sec\n","[2020-05-11 20:57:42,140 INFO] Step 4150/50000; acc:  28.26; ppl: 55.70; xent: 4.02; lr: 0.00051; 4538/1928 tok/s;   9021 sec\n","[2020-05-11 21:01:07,998 INFO] Step 4200/50000; acc:  27.88; ppl: 61.00; xent: 4.11; lr: 0.00052; 3521/2015 tok/s;   9227 sec\n","[2020-05-11 21:04:30,243 INFO] Step 4250/50000; acc:  29.87; ppl: 54.68; xent: 4.00; lr: 0.00052; 3635/1977 tok/s;   9429 sec\n","[2020-05-11 21:07:58,693 INFO] Step 4300/50000; acc:  29.01; ppl: 51.90; xent: 3.95; lr: 0.00053; 4189/1940 tok/s;   9638 sec\n","[2020-05-11 21:11:22,875 INFO] Step 4350/50000; acc:  30.36; ppl: 47.83; xent: 3.87; lr: 0.00054; 4501/1915 tok/s;   9842 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1hBOAwg9Dgnw","colab_type":"code","outputId":"119e1d05-4932-46d9-e4cc-6ce089b10ece","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python /content/drive/My\\ Drive/transformer/code/train.py -save_model /content/drive/My\\ Drive/transformer/model_transformer_1000/transformer_1000 \\\n","        -data /content/drive/My\\ Drive/transformer/data/transformer_prep_data \\\n","        -copy_attn -word_vec_size 512 -rnn_size 512 -layers 4 -encoder_type transformer -decoder_type transformer -position_encoding \\\n","        -train_steps 50000 -warmup_steps 8000 -learning_rate 2 -decay_method noam -label_smoothing 0.1 -max_grad_norm 0 -dropout 0.2 \\\n","        -batch_size 4096 -optim adam -adam_beta2 0.998 -param_init 0 -batch_type tokens -normalization tokens -max_generator_batches 2 \\\n","        -accum_count 4 -share_embeddings -param_init_glorot -seed 777 -world_size 1 -gpu_ranks 0 -save_checkpoint_steps 1000 -train_from /content/drive/My\\ Drive/transformer/model_transformer_1000/transformer_1000_step_10000.pt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[2020-05-12 17:30:45,988 INFO] Loading checkpoint from /content/drive/My Drive/transformer/model_transformer_1000/transformer_1000_step_10000.pt\n","[2020-05-12 17:31:11,705 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","[2020-05-12 17:31:11,705 INFO] Loading vocab from checkpoint at /content/drive/My Drive/transformer/model_transformer_1000/transformer_1000_step_10000.pt.\n","[2020-05-12 17:31:11,780 INFO]  * vocabulary size. source = 50004; target = 50004\n","[2020-05-12 17:31:11,780 INFO] Building model...\n","[2020-05-12 17:31:22,767 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(50004, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.2)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm): LayerNorm()\n","        (dropout): Dropout(p=0.2)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm): LayerNorm()\n","        (dropout): Dropout(p=0.2)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm): LayerNorm()\n","        (dropout): Dropout(p=0.2)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm): LayerNorm()\n","        (dropout): Dropout(p=0.2)\n","      )\n","    )\n","    (layer_norm): LayerNorm()\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(50004, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.2)\n","        )\n","      )\n","    )\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm()\n","        (layer_norm_2): LayerNorm()\n","        (drop): Dropout(p=0.2)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm()\n","        (layer_norm_2): LayerNorm()\n","        (drop): Dropout(p=0.2)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm()\n","        (layer_norm_2): LayerNorm()\n","        (drop): Dropout(p=0.2)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax()\n","          (dropout): Dropout(p=0.2)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm()\n","          (dropout_1): Dropout(p=0.2)\n","          (relu): ReLU()\n","          (dropout_2): Dropout(p=0.2)\n","        )\n","        (layer_norm_1): LayerNorm()\n","        (layer_norm_2): LayerNorm()\n","        (drop): Dropout(p=0.2)\n","      )\n","    )\n","    (copy_attn): GlobalAttention(\n","      (linear_in): Linear(in_features=512, out_features=512, bias=False)\n","      (linear_out): Linear(in_features=1024, out_features=512, bias=False)\n","    )\n","    (layer_norm): LayerNorm()\n","  )\n","  (generator): CopyGenerator(\n","    (linear): Linear(in_features=512, out_features=50004, bias=True)\n","    (linear_copy): Linear(in_features=512, out_features=1, bias=True)\n","    (softmax): Softmax()\n","    (sigmoid): Sigmoid()\n","  )\n",")\n","[2020-05-12 17:31:22,771 INFO] encoder: 38212608\n","[2020-05-12 17:31:22,771 INFO] decoder: 43256149\n","[2020-05-12 17:31:22,771 INFO] * number of parameters: 81468757\n","[2020-05-12 17:31:23,288 INFO] Start training...\n","[2020-05-12 17:31:30,935 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","/usr/local/lib/python3.7/site-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  var = torch.tensor(arr, dtype=self.dtype, device=device)\n","[2020-05-12 17:35:02,321 INFO] Step 10050/50000; acc:  38.11; ppl: 24.67; xent: 3.21; lr: 0.00088; 3565/1745 tok/s;    211 sec\n","[2020-05-12 17:38:35,980 INFO] Step 10100/50000; acc:  36.14; ppl: 26.55; xent: 3.28; lr: 0.00088; 4871/1816 tok/s;    425 sec\n","[2020-05-12 17:42:03,761 INFO] Step 10150/50000; acc:  32.29; ppl: 32.60; xent: 3.48; lr: 0.00088; 4024/1863 tok/s;    633 sec\n","[2020-05-12 17:45:32,945 INFO] Step 10200/50000; acc:  37.98; ppl: 26.15; xent: 3.26; lr: 0.00088; 3608/1905 tok/s;    842 sec\n","[2020-05-12 17:48:58,891 INFO] Step 10250/50000; acc:  34.26; ppl: 27.37; xent: 3.31; lr: 0.00087; 4531/1878 tok/s;   1048 sec\n","[2020-05-12 17:52:23,828 INFO] Step 10300/50000; acc:  34.42; ppl: 30.03; xent: 3.40; lr: 0.00087; 3753/1978 tok/s;   1253 sec\n","[2020-05-12 17:55:50,102 INFO] Step 10350/50000; acc:  32.84; ppl: 34.14; xent: 3.53; lr: 0.00087; 3526/1966 tok/s;   1459 sec\n","[2020-05-12 17:59:15,410 INFO] Step 10400/50000; acc:  38.48; ppl: 22.80; xent: 3.13; lr: 0.00087; 3865/1841 tok/s;   1664 sec\n","[2020-05-12 18:02:43,366 INFO] Step 10450/50000; acc:  35.64; ppl: 27.87; xent: 3.33; lr: 0.00086; 3651/1959 tok/s;   1872 sec\n","[2020-05-12 18:06:11,709 INFO] Step 10500/50000; acc:  35.39; ppl: 27.67; xent: 3.32; lr: 0.00086; 4031/1903 tok/s;   2081 sec\n","[2020-05-12 18:09:40,197 INFO] Step 10550/50000; acc:  34.98; ppl: 29.23; xent: 3.38; lr: 0.00086; 3797/1917 tok/s;   2289 sec\n","[2020-05-12 18:13:06,423 INFO] Step 10600/50000; acc:  36.62; ppl: 27.71; xent: 3.32; lr: 0.00086; 3703/1994 tok/s;   2495 sec\n","[2020-05-12 18:15:07,959 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.2.pt, number of examples: 20478\n","[2020-05-12 18:16:44,593 INFO] Step 10650/50000; acc:  33.75; ppl: 34.17; xent: 3.53; lr: 0.00086; 3828/1964 tok/s;   2714 sec\n","[2020-05-12 18:20:11,929 INFO] Step 10700/50000; acc:  36.49; ppl: 25.69; xent: 3.25; lr: 0.00085; 3706/1981 tok/s;   2921 sec\n","[2020-05-12 18:23:30,894 INFO] Step 10750/50000; acc:  34.44; ppl: 28.65; xent: 3.36; lr: 0.00085; 4295/1945 tok/s;   3120 sec\n","[2020-05-12 18:26:55,215 INFO] Step 10800/50000; acc:  35.00; ppl: 30.26; xent: 3.41; lr: 0.00085; 3799/1990 tok/s;   3324 sec\n","[2020-05-12 18:30:16,176 INFO] Step 10850/50000; acc:  33.57; ppl: 31.06; xent: 3.44; lr: 0.00085; 4590/1925 tok/s;   3525 sec\n","[2020-05-12 18:33:40,747 INFO] Step 10900/50000; acc:  35.07; ppl: 30.31; xent: 3.41; lr: 0.00085; 3854/1993 tok/s;   3730 sec\n","[2020-05-12 18:37:06,219 INFO] Step 10950/50000; acc:  34.01; ppl: 31.58; xent: 3.45; lr: 0.00084; 3879/1932 tok/s;   3935 sec\n","[2020-05-12 18:40:32,651 INFO] Step 11000/50000; acc:  34.33; ppl: 29.06; xent: 3.37; lr: 0.00084; 3914/1998 tok/s;   4142 sec\n","[2020-05-12 18:40:32,652 INFO] Saving checkpoint /content/drive/My Drive/transformer/model_transformer_1000/transformer_1000_step_11000.pt\n","[2020-05-12 18:44:03,893 INFO] Step 11050/50000; acc:  36.05; ppl: 25.84; xent: 3.25; lr: 0.00084; 3871/1992 tok/s;   4353 sec\n","[2020-05-12 18:47:29,516 INFO] Step 11100/50000; acc:  33.05; ppl: 33.29; xent: 3.51; lr: 0.00084; 4612/1896 tok/s;   4559 sec\n","[2020-05-12 18:50:53,080 INFO] Step 11150/50000; acc:  36.04; ppl: 29.56; xent: 3.39; lr: 0.00084; 4210/1832 tok/s;   4762 sec\n","[2020-05-12 18:54:17,334 INFO] Step 11200/50000; acc:  36.48; ppl: 28.00; xent: 3.33; lr: 0.00084; 4976/1886 tok/s;   4966 sec\n","[2020-05-12 18:57:38,717 INFO] Step 11250/50000; acc:  35.20; ppl: 30.24; xent: 3.41; lr: 0.00083; 3997/1978 tok/s;   5168 sec\n","[2020-05-12 18:58:20,142 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.3.pt, number of examples: 4074\n","[2020-05-12 19:01:20,513 INFO] Step 11300/50000; acc:  33.95; ppl: 33.37; xent: 3.51; lr: 0.00083; 3669/1998 tok/s;   5390 sec\n","[2020-05-12 19:04:44,095 INFO] Step 11350/50000; acc:  34.53; ppl: 30.30; xent: 3.41; lr: 0.00083; 4262/1926 tok/s;   5593 sec\n","[2020-05-12 19:07:01,108 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","[2020-05-12 19:08:18,451 INFO] Step 11400/50000; acc:  38.28; ppl: 23.52; xent: 3.16; lr: 0.00083; 3602/1990 tok/s;   5808 sec\n","[2020-05-12 19:11:42,579 INFO] Step 11450/50000; acc:  37.30; ppl: 24.05; xent: 3.18; lr: 0.00083; 4414/1894 tok/s;   6012 sec\n","[2020-05-12 19:15:06,924 INFO] Step 11500/50000; acc:  36.77; ppl: 25.83; xent: 3.25; lr: 0.00082; 3588/1818 tok/s;   6216 sec\n","[2020-05-12 19:18:26,715 INFO] Step 11550/50000; acc:  33.72; ppl: 32.55; xent: 3.48; lr: 0.00082; 3370/2029 tok/s;   6416 sec\n","[2020-05-12 19:21:48,744 INFO] Step 11600/50000; acc:  35.28; ppl: 27.20; xent: 3.30; lr: 0.00082; 3681/1999 tok/s;   6618 sec\n","[2020-05-12 19:25:09,367 INFO] Step 11650/50000; acc:  40.18; ppl: 20.58; xent: 3.02; lr: 0.00082; 3644/1874 tok/s;   6818 sec\n","[2020-05-12 19:28:35,853 INFO] Step 11700/50000; acc:  37.86; ppl: 21.81; xent: 3.08; lr: 0.00082; 4608/1909 tok/s;   7025 sec\n","[2020-05-12 19:31:58,697 INFO] Step 11750/50000; acc:  39.05; ppl: 22.35; xent: 3.11; lr: 0.00082; 3184/1925 tok/s;   7228 sec\n","[2020-05-12 19:35:24,917 INFO] Step 11800/50000; acc:  36.85; ppl: 25.99; xent: 3.26; lr: 0.00081; 3456/1957 tok/s;   7434 sec\n","[2020-05-12 19:38:51,263 INFO] Step 11850/50000; acc:  34.60; ppl: 29.01; xent: 3.37; lr: 0.00081; 3997/1945 tok/s;   7640 sec\n","[2020-05-12 19:42:17,178 INFO] Step 11900/50000; acc:  37.72; ppl: 22.70; xent: 3.12; lr: 0.00081; 4101/1948 tok/s;   7846 sec\n","[2020-05-12 19:45:38,220 INFO] Step 11950/50000; acc:  40.48; ppl: 18.51; xent: 2.92; lr: 0.00081; 4740/1891 tok/s;   8047 sec\n","[2020-05-12 19:49:04,667 INFO] Step 12000/50000; acc:  36.21; ppl: 26.53; xent: 3.28; lr: 0.00081; 3951/1985 tok/s;   8254 sec\n","[2020-05-12 19:49:04,668 INFO] Saving checkpoint /content/drive/My Drive/transformer/model_transformer_1000/transformer_1000_step_12000.pt\n","[2020-05-12 19:49:59,940 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.2.pt, number of examples: 20478\n","[2020-05-12 19:52:54,910 INFO] Step 12050/50000; acc:  33.80; ppl: 28.89; xent: 3.36; lr: 0.00081; 4121/1970 tok/s;   8484 sec\n","[2020-05-12 19:56:20,135 INFO] Step 12100/50000; acc:  34.63; ppl: 27.27; xent: 3.31; lr: 0.00080; 3789/1987 tok/s;   8689 sec\n","[2020-05-12 19:59:38,183 INFO] Step 12150/50000; acc:  36.61; ppl: 23.17; xent: 3.14; lr: 0.00080; 4541/1929 tok/s;   8887 sec\n","[2020-05-12 20:03:03,203 INFO] Step 12200/50000; acc:  36.01; ppl: 26.63; xent: 3.28; lr: 0.00080; 3508/2008 tok/s;   9092 sec\n","[2020-05-12 20:06:24,476 INFO] Step 12250/50000; acc:  38.38; ppl: 24.08; xent: 3.18; lr: 0.00080; 3676/2000 tok/s;   9294 sec\n","[2020-05-12 20:09:52,427 INFO] Step 12300/50000; acc:  37.68; ppl: 23.43; xent: 3.15; lr: 0.00080; 4203/1946 tok/s;   9501 sec\n","[2020-05-12 20:13:16,222 INFO] Step 12350/50000; acc:  38.94; ppl: 20.93; xent: 3.04; lr: 0.00080; 4506/1917 tok/s;   9705 sec\n","[2020-05-12 20:16:43,523 INFO] Step 12400/50000; acc:  35.44; ppl: 28.66; xent: 3.36; lr: 0.00079; 3717/2000 tok/s;   9913 sec\n","[2020-05-12 20:20:09,213 INFO] Step 12450/50000; acc:  38.15; ppl: 23.48; xent: 3.16; lr: 0.00079; 3624/1867 tok/s;  10118 sec\n","[2020-05-12 20:23:36,186 INFO] Step 12500/50000; acc:  33.96; ppl: 31.04; xent: 3.44; lr: 0.00079; 3471/2019 tok/s;  10325 sec\n","[2020-05-12 20:26:59,042 INFO] Step 12550/50000; acc:  34.47; ppl: 29.70; xent: 3.39; lr: 0.00079; 3815/2005 tok/s;  10528 sec\n","[2020-05-12 20:30:21,555 INFO] Step 12600/50000; acc:  37.22; ppl: 23.55; xent: 3.16; lr: 0.00079; 4779/1658 tok/s;  10731 sec\n","[2020-05-12 20:33:00,654 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.3.pt, number of examples: 4074\n","[2020-05-12 20:33:50,268 INFO] Step 12650/50000; acc:  37.58; ppl: 25.21; xent: 3.23; lr: 0.00079; 3701/1984 tok/s;  10939 sec\n","[2020-05-12 20:37:18,140 INFO] Step 12700/50000; acc:  34.67; ppl: 29.71; xent: 3.39; lr: 0.00078; 4491/1838 tok/s;  11147 sec\n","[2020-05-12 20:40:41,563 INFO] Step 12750/50000; acc:  41.53; ppl: 20.47; xent: 3.02; lr: 0.00078; 4384/1887 tok/s;  11351 sec\n","[2020-05-12 20:41:45,554 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","[2020-05-12 20:44:17,366 INFO] Step 12800/50000; acc:  38.97; ppl: 23.50; xent: 3.16; lr: 0.00078; 3777/1981 tok/s;  11566 sec\n","[2020-05-12 20:47:46,201 INFO] Step 12850/50000; acc:  35.66; ppl: 28.45; xent: 3.35; lr: 0.00078; 3292/2015 tok/s;  11775 sec\n","[2020-05-12 20:51:09,257 INFO] Step 12900/50000; acc:  39.46; ppl: 20.61; xent: 3.03; lr: 0.00078; 3403/1790 tok/s;  11978 sec\n","[2020-05-12 20:54:31,942 INFO] Step 12950/50000; acc:  36.79; ppl: 24.23; xent: 3.19; lr: 0.00078; 3789/1978 tok/s;  12181 sec\n","[2020-05-12 20:57:54,081 INFO] Step 13000/50000; acc:  35.39; ppl: 24.76; xent: 3.21; lr: 0.00078; 4105/1936 tok/s;  12383 sec\n","[2020-05-12 20:57:54,082 INFO] Saving checkpoint /content/drive/My Drive/transformer/model_transformer_1000/transformer_1000_step_13000.pt\n","[2020-05-12 21:01:25,458 INFO] Step 13050/50000; acc:  36.21; ppl: 26.31; xent: 3.27; lr: 0.00077; 3743/1976 tok/s;  12595 sec\n","[2020-05-12 21:04:48,197 INFO] Step 13100/50000; acc:  34.46; ppl: 26.92; xent: 3.29; lr: 0.00077; 3560/1956 tok/s;  12797 sec\n","[2020-05-12 21:08:14,345 INFO] Step 13150/50000; acc:  39.34; ppl: 18.94; xent: 2.94; lr: 0.00077; 4668/1860 tok/s;  13003 sec\n","[2020-05-12 21:11:40,239 INFO] Step 13200/50000; acc:  38.41; ppl: 21.04; xent: 3.05; lr: 0.00077; 3678/2003 tok/s;  13209 sec\n","[2020-05-12 21:15:08,224 INFO] Step 13250/50000; acc:  38.15; ppl: 19.45; xent: 2.97; lr: 0.00077; 4619/1915 tok/s;  13417 sec\n","[2020-05-12 21:18:32,732 INFO] Step 13300/50000; acc:  36.90; ppl: 23.50; xent: 3.16; lr: 0.00077; 4369/1922 tok/s;  13622 sec\n","[2020-05-12 21:21:57,282 INFO] Step 13350/50000; acc:  37.40; ppl: 22.68; xent: 3.12; lr: 0.00076; 4045/1961 tok/s;  13826 sec\n","[2020-05-12 21:24:56,367 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.2.pt, number of examples: 20478\n","[2020-05-12 21:25:39,383 INFO] Step 13400/50000; acc:  39.70; ppl: 19.80; xent: 2.99; lr: 0.00076; 3806/1987 tok/s;  14048 sec\n","[2020-05-12 21:29:07,118 INFO] Step 13450/50000; acc:  33.77; ppl: 28.67; xent: 3.36; lr: 0.00076; 3606/1993 tok/s;  14256 sec\n","[2020-05-12 21:32:29,496 INFO] Step 13500/50000; acc:  34.73; ppl: 27.19; xent: 3.30; lr: 0.00076; 3989/1945 tok/s;  14459 sec\n","[2020-05-12 21:35:53,860 INFO] Step 13550/50000; acc:  35.24; ppl: 23.89; xent: 3.17; lr: 0.00076; 3990/1962 tok/s;  14663 sec\n","[2020-05-12 21:39:19,664 INFO] Step 13600/50000; acc:  39.14; ppl: 20.16; xent: 3.00; lr: 0.00076; 4169/1809 tok/s;  14869 sec\n","[2020-05-12 21:42:45,534 INFO] Step 13650/50000; acc:  37.74; ppl: 21.85; xent: 3.08; lr: 0.00076; 4309/1924 tok/s;  15075 sec\n","[2020-05-12 21:46:11,750 INFO] Step 13700/50000; acc:  36.62; ppl: 24.54; xent: 3.20; lr: 0.00076; 3851/1972 tok/s;  15281 sec\n","[2020-05-12 21:49:38,398 INFO] Step 13750/50000; acc:  38.99; ppl: 22.18; xent: 3.10; lr: 0.00075; 3733/1967 tok/s;  15487 sec\n","[2020-05-12 21:53:05,939 INFO] Step 13800/50000; acc:  41.02; ppl: 17.94; xent: 2.89; lr: 0.00075; 4526/1900 tok/s;  15695 sec\n","[2020-05-12 21:56:35,541 INFO] Step 13850/50000; acc:  36.78; ppl: 24.05; xent: 3.18; lr: 0.00075; 4097/1958 tok/s;  15905 sec\n","[2020-05-12 22:00:00,952 INFO] Step 13900/50000; acc:  35.09; ppl: 25.61; xent: 3.24; lr: 0.00075; 4114/1952 tok/s;  16110 sec\n","[2020-05-12 22:03:25,676 INFO] Step 13950/50000; acc:  35.70; ppl: 26.66; xent: 3.28; lr: 0.00075; 4188/1954 tok/s;  16315 sec\n","[2020-05-12 22:06:49,022 INFO] Step 14000/50000; acc:  38.97; ppl: 21.79; xent: 3.08; lr: 0.00075; 3926/1971 tok/s;  16518 sec\n","[2020-05-12 22:06:49,023 INFO] Saving checkpoint /content/drive/My Drive/transformer/model_transformer_1000/transformer_1000_step_14000.pt\n","[2020-05-12 22:08:17,181 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.3.pt, number of examples: 4074\n","[2020-05-12 22:10:23,660 INFO] Step 14050/50000; acc:  33.80; ppl: 29.44; xent: 3.38; lr: 0.00075; 3640/1988 tok/s;  16733 sec\n","[2020-05-12 22:13:52,041 INFO] Step 14100/50000; acc:  38.94; ppl: 20.23; xent: 3.01; lr: 0.00074; 4322/1924 tok/s;  16941 sec\n","[2020-05-12 22:17:12,301 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","[2020-05-12 22:17:32,443 INFO] Step 14150/50000; acc:  37.07; ppl: 23.27; xent: 3.15; lr: 0.00074; 3925/1972 tok/s;  17162 sec\n","[2020-05-12 22:20:58,046 INFO] Step 14200/50000; acc:  37.39; ppl: 24.18; xent: 3.19; lr: 0.00074; 3487/1918 tok/s;  17367 sec\n","[2020-05-12 22:24:24,751 INFO] Step 14250/50000; acc:  40.81; ppl: 17.79; xent: 2.88; lr: 0.00074; 4531/1905 tok/s;  17574 sec\n","[2020-05-12 22:27:46,177 INFO] Step 14300/50000; acc:  40.74; ppl: 19.54; xent: 2.97; lr: 0.00074; 3802/1975 tok/s;  17775 sec\n","[2020-05-12 22:31:08,662 INFO] Step 14350/50000; acc:  41.89; ppl: 16.89; xent: 2.83; lr: 0.00074; 4252/1905 tok/s;  17978 sec\n","[2020-05-12 22:34:29,833 INFO] Step 14400/50000; acc:  39.76; ppl: 19.92; xent: 2.99; lr: 0.00074; 3989/1956 tok/s;  18179 sec\n","[2020-05-12 22:37:55,621 INFO] Step 14450/50000; acc:  36.02; ppl: 24.72; xent: 3.21; lr: 0.00074; 3317/1798 tok/s;  18385 sec\n","[2020-05-12 22:41:19,435 INFO] Step 14500/50000; acc:  39.28; ppl: 20.27; xent: 3.01; lr: 0.00073; 4195/1940 tok/s;  18589 sec\n","[2020-05-12 22:44:44,786 INFO] Step 14550/50000; acc:  37.84; ppl: 24.24; xent: 3.19; lr: 0.00073; 3433/2000 tok/s;  18794 sec\n","[2020-05-12 22:48:10,807 INFO] Step 14600/50000; acc:  37.44; ppl: 21.93; xent: 3.09; lr: 0.00073; 3984/1956 tok/s;  19000 sec\n","[2020-05-12 22:51:37,239 INFO] Step 14650/50000; acc:  37.87; ppl: 20.85; xent: 3.04; lr: 0.00073; 4120/1930 tok/s;  19206 sec\n","[2020-05-12 22:55:01,776 INFO] Step 14700/50000; acc:  37.76; ppl: 21.42; xent: 3.06; lr: 0.00073; 4049/1965 tok/s;  19411 sec\n","[2020-05-12 22:58:26,451 INFO] Step 14750/50000; acc:  38.35; ppl: 20.94; xent: 3.04; lr: 0.00073; 4055/1948 tok/s;  19616 sec\n","[2020-05-12 23:00:04,550 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.2.pt, number of examples: 20478\n","[2020-05-12 23:02:00,736 INFO] Step 14800/50000; acc:  39.02; ppl: 19.46; xent: 2.97; lr: 0.00073; 4250/1917 tok/s;  19830 sec\n","[2020-05-12 23:05:29,205 INFO] Step 14850/50000; acc:  37.05; ppl: 22.11; xent: 3.10; lr: 0.00073; 4272/1950 tok/s;  20038 sec\n","[2020-05-12 23:08:49,426 INFO] Step 14900/50000; acc:  36.59; ppl: 22.27; xent: 3.10; lr: 0.00072; 4253/1868 tok/s;  20238 sec\n","[2020-05-12 23:12:15,032 INFO] Step 14950/50000; acc:  39.30; ppl: 18.99; xent: 2.94; lr: 0.00072; 3655/1994 tok/s;  20444 sec\n","[2020-05-12 23:15:36,972 INFO] Step 15000/50000; acc:  37.95; ppl: 22.57; xent: 3.12; lr: 0.00072; 3899/1967 tok/s;  20646 sec\n","[2020-05-12 23:15:36,973 INFO] Saving checkpoint /content/drive/My Drive/transformer/model_transformer_1000/transformer_1000_step_15000.pt\n","[2020-05-12 23:19:10,613 INFO] Step 15050/50000; acc:  38.30; ppl: 21.51; xent: 3.07; lr: 0.00072; 3763/1989 tok/s;  20860 sec\n","[2020-05-12 23:22:36,510 INFO] Step 15100/50000; acc:  37.41; ppl: 24.39; xent: 3.19; lr: 0.00072; 4106/1963 tok/s;  21066 sec\n","[2020-05-12 23:26:02,852 INFO] Step 15150/50000; acc:  37.40; ppl: 22.42; xent: 3.11; lr: 0.00072; 4323/1924 tok/s;  21272 sec\n","[2020-05-12 23:29:27,500 INFO] Step 15200/50000; acc:  36.09; ppl: 24.81; xent: 3.21; lr: 0.00072; 3766/1994 tok/s;  21477 sec\n","[2020-05-12 23:32:54,771 INFO] Step 15250/50000; acc:  38.37; ppl: 22.01; xent: 3.09; lr: 0.00072; 3580/1768 tok/s;  21684 sec\n","[2020-05-12 23:36:18,752 INFO] Step 15300/50000; acc:  40.54; ppl: 18.02; xent: 2.89; lr: 0.00071; 4493/1940 tok/s;  21888 sec\n","[2020-05-12 23:39:44,514 INFO] Step 15350/50000; acc:  36.98; ppl: 23.78; xent: 3.17; lr: 0.00071; 3670/1986 tok/s;  22094 sec\n","[2020-05-12 23:43:07,098 INFO] Step 15400/50000; acc:  39.05; ppl: 22.00; xent: 3.09; lr: 0.00071; 3616/1980 tok/s;  22296 sec\n","[2020-05-12 23:43:14,107 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.3.pt, number of examples: 4074\n","[2020-05-12 23:46:35,767 INFO] Step 15450/50000; acc:  36.67; ppl: 24.76; xent: 3.21; lr: 0.00071; 3692/2001 tok/s;  22505 sec\n","[2020-05-12 23:50:00,638 INFO] Step 15500/50000; acc:  39.12; ppl: 20.07; xent: 3.00; lr: 0.00071; 4130/1944 tok/s;  22710 sec\n","[2020-05-12 23:52:02,493 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","[2020-05-12 23:53:37,451 INFO] Step 15550/50000; acc:  34.53; ppl: 25.89; xent: 3.25; lr: 0.00071; 3359/2020 tok/s;  22927 sec\n","[2020-05-12 23:57:02,969 INFO] Step 15600/50000; acc:  41.60; ppl: 17.13; xent: 2.84; lr: 0.00071; 3841/1671 tok/s;  23132 sec\n","[2020-05-13 00:00:27,786 INFO] Step 15650/50000; acc:  39.30; ppl: 19.68; xent: 2.98; lr: 0.00071; 3791/1991 tok/s;  23337 sec\n","[2020-05-13 00:03:47,513 INFO] Step 15700/50000; acc:  39.37; ppl: 19.80; xent: 2.99; lr: 0.00071; 4333/1939 tok/s;  23537 sec\n","[2020-05-13 00:07:10,015 INFO] Step 15750/50000; acc:  40.47; ppl: 17.68; xent: 2.87; lr: 0.00070; 4332/1921 tok/s;  23739 sec\n","[2020-05-13 00:10:31,425 INFO] Step 15800/50000; acc:  38.45; ppl: 20.89; xent: 3.04; lr: 0.00070; 3669/1978 tok/s;  23940 sec\n","[2020-05-13 00:13:57,562 INFO] Step 15850/50000; acc:  37.25; ppl: 22.61; xent: 3.12; lr: 0.00070; 3686/1986 tok/s;  24147 sec\n","[2020-05-13 00:17:22,547 INFO] Step 15900/50000; acc:  38.02; ppl: 21.82; xent: 3.08; lr: 0.00070; 3355/2001 tok/s;  24352 sec\n","[2020-05-13 00:20:45,692 INFO] Step 15950/50000; acc:  39.21; ppl: 18.69; xent: 2.93; lr: 0.00070; 4293/1919 tok/s;  24555 sec\n","[2020-05-13 00:24:13,712 INFO] Step 16000/50000; acc:  38.98; ppl: 18.53; xent: 2.92; lr: 0.00070; 3924/1963 tok/s;  24763 sec\n","[2020-05-13 00:24:13,713 INFO] Saving checkpoint /content/drive/My Drive/transformer/model_transformer_1000/transformer_1000_step_16000.pt\n","[2020-05-13 00:27:46,500 INFO] Step 16050/50000; acc:  38.89; ppl: 21.80; xent: 3.08; lr: 0.00070; 3582/1953 tok/s;  24976 sec\n","[2020-05-13 00:31:08,939 INFO] Step 16100/50000; acc:  38.23; ppl: 20.45; xent: 3.02; lr: 0.00070; 3888/1960 tok/s;  25178 sec\n","[2020-05-13 00:34:36,051 INFO] Step 16150/50000; acc:  37.33; ppl: 21.99; xent: 3.09; lr: 0.00070; 3988/1979 tok/s;  25385 sec\n","[2020-05-13 00:35:00,224 INFO] Loading train dataset from /content/drive/My Drive/transformer/data/transformer_prep_data.train.2.pt, number of examples: 20478\n","[2020-05-13 00:38:10,707 INFO] Step 16200/50000; acc:  37.63; ppl: 20.49; xent: 3.02; lr: 0.00069; 4467/1899 tok/s;  25600 sec\n","[2020-05-13 00:41:36,872 INFO] Step 16250/50000; acc:  42.53; ppl: 16.08; xent: 2.78; lr: 0.00069; 4364/1944 tok/s;  25806 sec\n","[2020-05-13 00:44:57,484 INFO] Step 16300/50000; acc:  37.00; ppl: 22.91; xent: 3.13; lr: 0.00069; 3273/2091 tok/s;  26007 sec\n","[2020-05-13 00:48:22,409 INFO] Step 16350/50000; acc:  41.38; ppl: 15.56; xent: 2.74; lr: 0.00069; 3791/1713 tok/s;  26211 sec\n","[2020-05-13 00:51:45,771 INFO] Step 16400/50000; acc:  45.76; ppl: 13.40; xent: 2.60; lr: 0.00069; 3796/1844 tok/s;  26415 sec\n","[2020-05-13 00:55:14,313 INFO] Step 16450/50000; acc:  37.31; ppl: 22.88; xent: 3.13; lr: 0.00069; 3519/2008 tok/s;  26623 sec\n","[2020-05-13 00:58:37,711 INFO] Step 16500/50000; acc:  41.01; ppl: 17.98; xent: 2.89; lr: 0.00069; 4038/1970 tok/s;  26827 sec\n","[2020-05-13 01:02:05,614 INFO] Step 16550/50000; acc:  41.15; ppl: 17.02; xent: 2.83; lr: 0.00069; 5156/1847 tok/s;  27035 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y1GUUNtX_Rch","colab_type":"code","colab":{}},"source":["# [2020-05-13 11:26:58,682 INFO] Loading train dataset from /home/mkrilov/Thesis/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","# /home/mkrilov/miniconda3/envs/thesis_py3.6_torch1.1/lib/python3.6/site-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","#   var = torch.tensor(arr, dtype=self.dtype, device=device)\n","# [2020-05-13 11:30:50,670 INFO] Step 16050/50000; acc:  43.60; ppl: 14.55; xent: 2.68; lr: 0.00070; 3183/1558 tok/s;    232 sec\n","# [2020-05-13 11:34:38,709 INFO] Step 16100/50000; acc:  43.60; ppl: 14.09; xent: 2.65; lr: 0.00070; 5026/1874 tok/s;    460 sec\n","# [2020-05-13 11:38:27,023 INFO] Step 16150/50000; acc:  39.35; ppl: 17.63; xent: 2.87; lr: 0.00070; 3370/1560 tok/s;    688 sec\n","# [2020-05-13 11:42:18,843 INFO] Step 16200/50000; acc:  44.14; ppl: 15.05; xent: 2.71; lr: 0.00069; 3640/1922 tok/s;    920 sec\n","# [2020-05-13 11:46:06,884 INFO] Step 16250/50000; acc:  42.55; ppl: 14.64; xent: 2.68; lr: 0.00069; 3892/1613 tok/s;   1148 sec\n","# [2020-05-13 11:49:49,084 INFO] Step 16300/50000; acc:  40.37; ppl: 17.52; xent: 2.86; lr: 0.00069; 3806/2006 tok/s;   1370 sec\n","# [2020-05-13 11:53:36,201 INFO] Step 16350/50000; acc:  38.34; ppl: 19.87; xent: 2.99; lr: 0.00069; 2982/1662 tok/s;   1598 sec\n","# [2020-05-13 11:57:24,380 INFO] Step 16400/50000; acc:  43.82; ppl: 13.43; xent: 2.60; lr: 0.00069; 3483/1659 tok/s;   1826 sec\n","# [2020-05-13 12:01:15,946 INFO] Step 16450/50000; acc:  39.95; ppl: 17.08; xent: 2.84; lr: 0.00069; 3326/1784 tok/s;   2057 sec\n","# [2020-05-13 12:05:05,771 INFO] Step 16500/50000; acc:  38.81; ppl: 20.11; xent: 3.00; lr: 0.00069; 3614/1706 tok/s;   2287 sec\n","# [2020-05-13 12:08:52,417 INFO] Step 16550/50000; acc:  37.85; ppl: 21.63; xent: 3.07; lr: 0.00069; 3937/1988 tok/s;   2514 sec\n","# [2020-05-13 12:12:33,540 INFO] Step 16600/50000; acc:  39.96; ppl: 20.20; xent: 3.01; lr: 0.00069; 3491/1880 tok/s;   2735 sec\n","# [2020-05-13 12:14:46,188 INFO] Loading train dataset from /home/mkrilov/Thesis/data/transformer_prep_data.train.2.pt, number of examples: 20478\n","# [2020-05-13 12:16:34,282 INFO] Step 16650/50000; acc:  36.28; ppl: 25.08; xent: 3.22; lr: 0.00068; 3392/1740 tok/s;   2976 sec\n","# [2020-05-13 12:20:28,229 INFO] Step 16700/50000; acc:  40.28; ppl: 18.70; xent: 2.93; lr: 0.00068; 3033/1621 tok/s;   3210 sec\n","# [2020-05-13 12:24:15,608 INFO] Step 16750/50000; acc:  37.36; ppl: 20.46; xent: 3.02; lr: 0.00068; 4368/1979 tok/s;   3437 sec\n","# [2020-05-13 12:28:00,173 INFO] Step 16800/50000; acc:  37.97; ppl: 22.43; xent: 3.11; lr: 0.00068; 3455/1811 tok/s;   3661 sec\n","# [2020-05-13 12:31:44,233 INFO] Step 16850/50000; acc:  38.02; ppl: 21.55; xent: 3.07; lr: 0.00068; 4725/1982 tok/s;   3886 sec\n","# [2020-05-13 12:35:30,863 INFO] Step 16900/50000; acc:  38.38; ppl: 21.91; xent: 3.09; lr: 0.00068; 3457/1787 tok/s;   4112 sec\n","# [2020-05-13 12:39:18,055 INFO] Step 16950/50000; acc:  37.64; ppl: 22.34; xent: 3.11; lr: 0.00068; 4025/2004 tok/s;   4339 sec\n","# [2020-05-13 12:43:02,870 INFO] Step 17000/50000; acc:  37.93; ppl: 20.50; xent: 3.02; lr: 0.00068; 3865/1973 tok/s;   4564 sec\n","# [2020-05-13 12:43:02,871 INFO] Saving checkpoint model_transformer_new500_colab/transformer_1000_step_17000.pt\n","# [2020-05-13 12:46:50,210 INFO] Step 17050/50000; acc:  40.10; ppl: 18.83; xent: 2.94; lr: 0.00068; 3410/1754 tok/s;   4792 sec\n","# [2020-05-13 12:50:31,603 INFO] Step 17100/50000; acc:  37.96; ppl: 20.58; xent: 3.02; lr: 0.00068; 4314/1774 tok/s;   5013 sec\n","# [2020-05-13 12:54:12,778 INFO] Step 17150/50000; acc:  40.12; ppl: 19.44; xent: 2.97; lr: 0.00067; 3555/1547 tok/s;   5234 sec\n","# [2020-05-13 12:57:52,016 INFO] Step 17200/50000; acc:  41.75; ppl: 17.43; xent: 2.86; lr: 0.00067; 4628/1754 tok/s;   5453 sec\n","# [2020-05-13 13:01:34,073 INFO] Step 17250/50000; acc:  39.12; ppl: 20.05; xent: 3.00; lr: 0.00067; 3605/1784 tok/s;   5675 sec\n","# [2020-05-13 13:02:05,539 INFO] Loading train dataset from /home/mkrilov/Thesis/data/transformer_prep_data.train.3.pt, number of examples: 4074\n","# [2020-05-13 13:05:24,043 INFO] Step 17300/50000; acc:  37.86; ppl: 22.08; xent: 3.09; lr: 0.00067; 3303/1799 tok/s;   5905 sec\n","# [2020-05-13 13:09:06,880 INFO] Step 17350/50000; acc:  39.27; ppl: 19.36; xent: 2.96; lr: 0.00067; 3714/1678 tok/s;   6128 sec\n","# [2020-05-13 13:11:33,937 INFO] Loading train dataset from /home/mkrilov/Thesis/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","# [2020-05-13 13:12:58,134 INFO] Step 17400/50000; acc:  43.02; ppl: 15.54; xent: 2.74; lr: 0.00067; 3676/2031 tok/s;   6359 sec\n","# [2020-05-13 13:16:38,829 INFO] Step 17450/50000; acc:  43.02; ppl: 14.56; xent: 2.68; lr: 0.00067; 3853/1653 tok/s;   6580 sec\n","# [2020-05-13 13:20:19,817 INFO] Step 17500/50000; acc:  41.18; ppl: 16.49; xent: 2.80; lr: 0.00067; 3264/1654 tok/s;   6801 sec\n","# [2020-05-13 13:23:54,344 INFO] Step 17550/50000; acc:  37.29; ppl: 21.29; xent: 3.06; lr: 0.00067; 3113/1874 tok/s;   7016 sec\n","# [2020-05-13 13:27:34,719 INFO] Step 17600/50000; acc:  40.45; ppl: 16.91; xent: 2.83; lr: 0.00067; 3801/2064 tok/s;   7236 sec\n","# [2020-05-13 13:31:15,722 INFO] Step 17650/50000; acc:  44.61; ppl: 13.62; xent: 2.61; lr: 0.00067; 3654/1879 tok/s;   7457 sec\n","# [2020-05-13 13:35:03,049 INFO] Step 17700/50000; acc:  43.06; ppl: 14.04; xent: 2.64; lr: 0.00066; 4226/1751 tok/s;   7684 sec\n","# [2020-05-13 13:38:45,677 INFO] Step 17750/50000; acc:  43.97; ppl: 14.85; xent: 2.70; lr: 0.00066; 3228/1951 tok/s;   7907 sec\n","# [2020-05-13 13:42:29,564 INFO] Step 17800/50000; acc:  41.81; ppl: 16.38; xent: 2.80; lr: 0.00066; 2980/1688 tok/s;   8131 sec\n","# [2020-05-13 13:46:14,367 INFO] Step 17850/50000; acc:  39.22; ppl: 18.47; xent: 2.92; lr: 0.00066; 4042/1967 tok/s;   8356 sec\n","# [2020-05-13 13:50:01,361 INFO] Step 17900/50000; acc:  41.14; ppl: 16.70; xent: 2.82; lr: 0.00066; 3348/1591 tok/s;   8583 sec\n","# [2020-05-13 13:53:43,904 INFO] Step 17950/50000; acc:  44.97; ppl: 13.42; xent: 2.60; lr: 0.00066; 4288/1711 tok/s;   8805 sec\n","# [2020-05-13 13:57:34,676 INFO] Step 18000/50000; acc:  40.04; ppl: 19.44; xent: 2.97; lr: 0.00066; 4020/2020 tok/s;   9036 sec\n","# [2020-05-13 13:57:34,678 INFO] Saving checkpoint model_transformer_new500_colab/transformer_1000_step_18000.pt\n","# [2020-05-13 13:58:20,933 INFO] Loading train dataset from /home/mkrilov/Thesis/data/transformer_prep_data.train.2.pt, number of examples: 20478\n","# [2020-05-13 14:01:27,443 INFO] Step 18050/50000; acc:  37.63; ppl: 20.84; xent: 3.04; lr: 0.00066; 4199/2007 tok/s;   9269 sec\n","# [2020-05-13 14:05:13,081 INFO] Step 18100/50000; acc:  38.32; ppl: 19.96; xent: 2.99; lr: 0.00066; 3305/1734 tok/s;   9494 sec\n","# [2020-05-13 14:08:53,184 INFO] Step 18150/50000; acc:  41.53; ppl: 16.20; xent: 2.79; lr: 0.00066; 4559/1937 tok/s;   9714 sec\n","# [2020-05-13 14:12:37,189 INFO] Step 18200/50000; acc:  39.07; ppl: 19.85; xent: 2.99; lr: 0.00066; 2928/1676 tok/s;   9938 sec\n","# [2020-05-13 14:16:16,117 INFO] Step 18250/50000; acc:  41.79; ppl: 17.36; xent: 2.85; lr: 0.00065; 3513/1911 tok/s;  10157 sec\n","# [2020-05-13 14:20:03,454 INFO] Step 18300/50000; acc:  41.66; ppl: 17.08; xent: 2.84; lr: 0.00065; 3609/1671 tok/s;  10385 sec\n","# [2020-05-13 14:23:49,268 INFO] Step 18350/50000; acc:  42.83; ppl: 15.06; xent: 2.71; lr: 0.00065; 4016/1709 tok/s;  10611 sec\n","# [2020-05-13 14:27:38,661 INFO] Step 18400/50000; acc:  39.11; ppl: 20.42; xent: 3.02; lr: 0.00065; 3376/1817 tok/s;  10840 sec\n","# [2020-05-13 14:31:28,643 INFO] Step 18450/50000; acc:  41.39; ppl: 17.33; xent: 2.85; lr: 0.00065; 3245/1671 tok/s;  11070 sec\n","# [2020-05-13 14:35:14,611 INFO] Step 18500/50000; acc:  36.81; ppl: 21.89; xent: 3.09; lr: 0.00065; 2969/1726 tok/s;  11296 sec\n","# [2020-05-13 14:38:56,579 INFO] Step 18550/50000; acc:  38.48; ppl: 21.03; xent: 3.05; lr: 0.00065; 3854/2025 tok/s;  11518 sec\n","# [2020-05-13 14:42:42,478 INFO] Step 18600/50000; acc:  42.06; ppl: 15.66; xent: 2.75; lr: 0.00065; 4332/1502 tok/s;  11744 sec\n","# [2020-05-13 14:45:35,069 INFO] Loading train dataset from /home/mkrilov/Thesis/data/transformer_prep_data.train.3.pt, number of examples: 4074\n","# [2020-05-13 14:46:29,259 INFO] Step 18650/50000; acc:  40.81; ppl: 18.15; xent: 2.90; lr: 0.00065; 3686/1976 tok/s;  11971 sec\n","# [2020-05-13 14:50:13,095 INFO] Step 18700/50000; acc:  38.55; ppl: 20.19; xent: 3.01; lr: 0.00065; 4045/1655 tok/s;  12194 sec\n","# [2020-05-13 14:53:54,036 INFO] Step 18750/50000; acc:  45.77; ppl: 13.95; xent: 2.64; lr: 0.00065; 3830/1648 tok/s;  12415 sec\n","# [2020-05-13 14:55:03,680 INFO] Loading train dataset from /home/mkrilov/Thesis/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","# [2020-05-13 14:57:51,882 INFO] Step 18800/50000; acc:  43.24; ppl: 15.75; xent: 2.76; lr: 0.00064; 3119/1636 tok/s;  12653 sec\n","# [2020-05-13 15:01:40,529 INFO] Step 18850/50000; acc:  39.40; ppl: 19.57; xent: 2.97; lr: 0.00064; 2789/1708 tok/s;  12882 sec\n","# [2020-05-13 15:05:25,122 INFO] Step 18900/50000; acc:  44.20; ppl: 14.04; xent: 2.64; lr: 0.00064; 3071/1616 tok/s;  13106 sec\n","# [2020-05-13 15:09:03,375 INFO] Step 18950/50000; acc:  41.61; ppl: 16.34; xent: 2.79; lr: 0.00064; 3524/1839 tok/s;  13325 sec\n","# [2020-05-13 15:12:43,211 INFO] Step 19000/50000; acc:  40.75; ppl: 16.22; xent: 2.79; lr: 0.00064; 3520/1659 tok/s;  13545 sec\n","# [2020-05-13 15:12:43,214 INFO] Saving checkpoint model_transformer_new500_colab/transformer_1000_step_19000.pt\n","# [2020-05-13 15:16:29,687 INFO] Step 19050/50000; acc:  41.10; ppl: 17.24; xent: 2.85; lr: 0.00064; 3827/2021 tok/s;  13771 sec\n","# [2020-05-13 15:20:12,267 INFO] Step 19100/50000; acc:  39.42; ppl: 18.10; xent: 2.90; lr: 0.00064; 3045/1673 tok/s;  13994 sec\n","# [2020-05-13 15:23:56,217 INFO] Step 19150/50000; acc:  44.64; ppl: 12.56; xent: 2.53; lr: 0.00064; 4289/1709 tok/s;  14218 sec\n","# [2020-05-13 15:27:43,312 INFO] Step 19200/50000; acc:  42.47; ppl: 14.76; xent: 2.69; lr: 0.00064; 3239/1763 tok/s;  14445 sec\n","# [2020-05-13 15:31:29,640 INFO] Step 19250/50000; acc:  42.87; ppl: 13.77; xent: 2.62; lr: 0.00064; 3924/1627 tok/s;  14671 sec\n","# [2020-05-13 15:35:13,650 INFO] Step 19300/50000; acc:  41.48; ppl: 16.67; xent: 2.81; lr: 0.00064; 3606/1586 tok/s;  14895 sec\n","# [2020-05-13 15:38:58,931 INFO] Step 19350/50000; acc:  40.92; ppl: 16.76; xent: 2.82; lr: 0.00064; 4026/1951 tok/s;  15120 sec\n","# [2020-05-13 15:42:14,826 INFO] Loading train dataset from /home/mkrilov/Thesis/data/transformer_prep_data.train.2.pt, number of examples: 20478\n","# [2020-05-13 15:43:01,387 INFO] Step 19400/50000; acc:  42.48; ppl: 15.26; xent: 2.73; lr: 0.00063; 3390/1769 tok/s;  15363 sec\n","# [2020-05-13 15:46:47,794 INFO] Step 19450/50000; acc:  36.64; ppl: 21.62; xent: 3.07; lr: 0.00063; 3647/2016 tok/s;  15589 sec\n","# [2020-05-13 15:50:36,578 INFO] Step 19500/50000; acc:  38.08; ppl: 20.18; xent: 3.00; lr: 0.00063; 3212/1566 tok/s;  15818 sec\n","# [2020-05-13 15:54:28,382 INFO] Step 19550/50000; acc:  39.55; ppl: 17.16; xent: 2.84; lr: 0.00063; 3733/1835 tok/s;  16050 sec\n","# [2020-05-13 15:58:14,997 INFO] Step 19600/50000; acc:  42.98; ppl: 14.92; xent: 2.70; lr: 0.00063; 3539/1535 tok/s;  16276 sec\n","# [2020-05-13 16:02:00,159 INFO] Step 19650/50000; acc:  42.15; ppl: 15.94; xent: 2.77; lr: 0.00063; 3695/1650 tok/s;  16501 sec\n","# [2020-05-13 16:05:43,420 INFO] Step 19700/50000; acc:  40.14; ppl: 17.86; xent: 2.88; lr: 0.00063; 3855/1974 tok/s;  16725 sec\n","# [2020-05-13 16:09:36,712 INFO] Step 19750/50000; acc:  42.47; ppl: 16.77; xent: 2.82; lr: 0.00063; 3117/1642 tok/s;  16958 sec\n","# [2020-05-13 16:13:30,915 INFO] Step 19800/50000; acc:  45.29; ppl: 12.92; xent: 2.56; lr: 0.00063; 3722/1562 tok/s;  17192 sec\n","# [2020-05-13 16:17:25,693 INFO] Step 19850/50000; acc:  40.23; ppl: 17.60; xent: 2.87; lr: 0.00063; 3844/1837 tok/s;  17427 sec\n","# [2020-05-13 16:21:18,969 INFO] Step 19900/50000; acc:  38.92; ppl: 18.43; xent: 2.91; lr: 0.00063; 3589/1703 tok/s;  17660 sec\n","# [2020-05-13 16:25:11,638 INFO] Step 19950/50000; acc:  39.83; ppl: 18.43; xent: 2.91; lr: 0.00063; 4272/1993 tok/s;  17893 sec\n","# [2020-05-13 16:28:53,286 INFO] Step 20000/50000; acc:  42.38; ppl: 16.10; xent: 2.78; lr: 0.00063; 3566/1790 tok/s;  18115 sec\n","# [2020-05-13 16:28:57,150 INFO] Loading valid dataset from /home/mkrilov/Thesis/data/transformer_prep_data.valid.1.pt, number of examples: 5621\n","# [2020-05-13 16:30:52,942 INFO] Validation perplexity: 38.8948\n","# [2020-05-13 16:30:52,951 INFO] Validation accuracy: 36.2563\n","# [2020-05-13 16:30:52,953 INFO] Saving checkpoint model_transformer_new500_colab/transformer_1000_step_20000.pt\n","# [2020-05-13 16:32:29,924 INFO] Loading train dataset from /home/mkrilov/Thesis/data/transformer_prep_data.train.3.pt, number of examples: 4074\n","# [2020-05-13 16:34:55,751 INFO] Step 20050/50000; acc:  37.09; ppl: 22.02; xent: 3.09; lr: 0.00062; 2943/1607 tok/s;  18477 sec\n","# [2020-05-13 16:38:50,357 INFO] Step 20100/50000; acc:  43.11; ppl: 14.73; xent: 2.69; lr: 0.00062; 4127/1837 tok/s;  18712 sec\n","# [2020-05-13 16:42:27,350 INFO] Loading train dataset from /home/mkrilov/Thesis/data/transformer_prep_data.train.1.pt, number of examples: 20412\n","# [2020-05-13 16:42:48,826 INFO] Step 20150/50000; acc:  41.50; ppl: 16.31; xent: 2.79; lr: 0.00062; 3912/1965 tok/s;  18950 sec\n","# [2020-05-13 16:46:39,233 INFO] Step 20200/50000; acc:  41.08; ppl: 16.90; xent: 2.83; lr: 0.00062; 3310/1821 tok/s;  19181 sec\n","# [2020-05-13 16:50:28,343 INFO] Step 20250/50000; acc:  45.38; ppl: 12.30; xent: 2.51; lr: 0.00062; 4590/1930 tok/s;  19410 sec\n","# [2020-05-13 16:54:15,421 INFO] Step 20300/50000; acc:  43.94; ppl: 14.22; xent: 2.65; lr: 0.00062; 3115/1619 tok/s;  19637 sec\n","# [2020-05-13 16:58:00,193 INFO] Step 20350/50000; acc:  45.50; ppl: 11.91; xent: 2.48; lr: 0.00062; 4370/1958 tok/s;  19862 sec\n","# [2020-05-13 17:01:47,839 INFO] Step 20400/50000; acc:  44.34; ppl: 13.71; xent: 2.62; lr: 0.00062; 3526/1730 tok/s;  20089 sec\n","# [2020-05-13 17:05:42,002 INFO] Step 20450/50000; acc:  39.89; ppl: 17.64; xent: 2.87; lr: 0.00062; 2918/1582 tok/s;  20323 sec"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gyLUufR8_Rex","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hvenn_4Y_Rg8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ejRgeMSd_RjO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1aLMfuZvEhjjqPKAHVAp4AxgUXFwuxlEP"},"outputId":"9f5c7cca-873b-48dd-b7d7-22ec60f9260a","executionInfo":{"status":"ok","timestamp":1589407002026,"user_tz":-120,"elapsed":5808617,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}}},"source":["!python /content/drive/My\\ Drive/transformer/code/translate.py -gpu 0 \\\n","        -batch_size 8 \\\n","        -beam_size 5 \\\n","        -model /content/drive/My\\ Drive/transformer/model_transformer_1000/transformer_1000_step_20000.pt \\\n","        -src /content/drive/My\\ Drive/transformer/data/multi-news-original-src-cleaned-no-newlinechar-word_tokenizer_1000/test.src.cleaned.tokenized.truncated1000 \\\n","        -output /content/drive/My\\ Drive/transformer/model_transformer_1000/transformer_1000_step_20000_full.output \\\n","        -min_length 200 \\\n","        -max_length 300 \\\n","        -stepwise_penalty \\\n","        -coverage_penalty summary \\\n","        -beta 5 \\\n","        -length_penalty wu \\\n","        -alpha 0.9 \\\n","        -verbose \\\n","        -block_ngram_repeat 3 \\\n","        -ignore_when_blocking \".\" \"</t>\" \"<t>\" \"story_separator_special_tag\""],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"QHE_nPs-Dgp7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eXDNJqvcDgrp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kJUu_pmpDgvq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZnU6pTtNDgx3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y1FzM6cqDg0F","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sbd0Sk7HetbC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rc52w2u32Zui","colab_type":"text"},"source":["Inference"]},{"cell_type":"code","metadata":{"id":"AWhbuZ7R2aoa","colab_type":"code","outputId":"99a3e9cd-0044-48fb-c74f-ced935a25a00","executionInfo":{"status":"ok","timestamp":1589109438431,"user_tz":-120,"elapsed":7070918,"user":{"displayName":"Martin Kirilov","photoUrl":"","userId":"17848944391786745195"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"12_U5Ckd_QoStmsxxYWF7yppM913QsabG"}},"source":[" !python /content/drive/My\\ Drive/hi_map/code/translate.py -gpu 0 \\\n","        -batch_size 8 \\\n","        -beam_size 4 \\\n","        -model /content/drive/My\\ Drive/hi_map\\model_himap_1000/himap_colab_step_20000.pt \\\n","        -src /content/drive/My\\ Drive/hi_map/data/multi-news-original-src-cleaned-no-newlinechar-word_tokenizer_1000/test.src.cleaned.tokenized.truncated1000 \\\n","        -output /content/drive/My\\ Drive/hi_map\\model_himap_1000/himap_colab_step_20000_full.output \\\n","        -min_length 200 \\\n","        -max_length 300 \\\n","        -stepwise_penalty \\\n","        -coverage_penalty summary \\\n","        -beta 5 \\\n","        -length_penalty wu \\\n","        -alpha 0.9 \\\n","        -verbose \\\n","        -block_ngram_repeat 3 \\\n","        -ignore_when_blocking \"story_separator_special_tag\"\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"aczzwWNO3oYQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}